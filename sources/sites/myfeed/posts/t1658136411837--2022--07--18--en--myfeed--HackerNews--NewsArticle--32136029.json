{
  "@type": "NewsArticle",
  "identifier": "2022--07--18--en--myfeed--HackerNews--NewsArticle--32136029",
  "url": "https://news.ycombinator.com/item?id=32136029",
  "headline": "Bert-Large: Prune Once for DistilBERT Inference Performance",
  "publisher": {
    "@type": "Organization",
    "name": "HackerNews",
    "url": "https://news.ycombinator.com",
    "logo": "https://hn.buzzing.cc/avatar.png"
  },
  "description": "",
  "keywords": [],
  "author": {
    "@type": "Person",
    "name": "yoquan",
    "url": "https://news.ycombinator.com/user?id=yoquan"
  },
  "discussionUrl": "https://news.ycombinator.com/item?id=32136029",
  "sameAs": "https://old.reddit.com/r/MachineLearning/comments/w0ff29/r_bertlarge_prune_once_for_distilbert_inference/",
  "dateCreated": "2022-07-18T09:26:51.837Z",
  "datePublished": "2022-07-18T08:52:38.000Z",
  "dateModified": "2022-07-18T09:26:51.837Z",
  "interactionStatistic": [
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "LikeAction"
      },
      "userInteractionCount": 2
    },
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "CommentAction"
      },
      "userInteractionCount": 0
    }
  ],
  "headline_zh-Hans": "Bert-Large。为提高DistilBERT的推理性能而进行一次修剪\n",
  "headline_zh-Hant": "Bert-Large。為提高DistilBERT的推理性能而進行一次修剪\n",
  "@context": [
    "https://schema.org",
    {
      "@vocab": "http://schema.org/",
      "@language": "en",
      "headline_zh-Hans": {
        "@id": "headline",
        "@language": "zh-Hans"
      },
      "headline_zh-Hant": {
        "@id": "headline",
        "@language": "zh-Hant"
      },
      "@version": 1.1
    }
  ]
}