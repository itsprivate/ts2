{
  "@type": "NewsArticle",
  "identifier": "2022--03--07--en--myfeed--HackerNews--NewsArticle--30591874",
  "url": "https://news.ycombinator.com/item?id=30591874",
  "headline": "Launch HN: Litebulb (YC W22) – Automating the technical interview",
  "publisher": {
    "@type": "Organization",
    "name": "HackerNews",
    "url": "https://news.ycombinator.com",
    "logo": "https://hn.buzzing.cc/avatar.png"
  },
  "description": "Hi HN, I’m Gary from Litebulb (<a href=\"https://litebulb.io\" rel=\"nofollow\">https://litebulb.io</a>). We automate technical onsite interviews for remote teams. When I say “automate”, I should add “as much as possible”. Our software doesn’t decide who you should hire! But we set up dev environments for interviews, ask questions on real codebases, track candidates, run tests to verify correctness, and analyze the code submitted. On the roadmap are things like scheduling, tracking timing, and customizing questions.<p>I've been a software engineer at 11 companies and have gone through well over a hundred interviewing funnels. Tech interviews suck. Engineers grind LeetCode for months just so they can write the optimal quicksort solution in 15 minutes, but on the job you just import it from some library like you're supposed to. My friends and I memorized half of HackerRank just to stack up job offers, but none of these recruiting teams actually knew whether or not we were good fits for the roles. In some cases we weren't.<p>After I went to the other side of the interviewing table, it got worse. It takes days to create a good interview, and engineers hate running repetitive, multi-hour interviews for people they likely won't ever see again. They get pulled away from dev work to do interviews, then have to sync up with the rest of the team to decide what everyone thinks and come to an often arbitrary decision. At some point, HR comes back to eng and asks them to fix or upgrade a 2 year old interview question, and nobody wants to or has the time. Having talked with hundreds of hiring managers, VPs of eng, heads of HR, and CTOs, I know how common this problem is. Common enough to warrant starting a startup, hence Litebulb.<p>We don’t do LeetCode—our interviews are like regular dev work. Candidates get access to an existing codebase on Github complete with a DB, server, and client. Environments are Dockerized, and every interview's setup is boiled down to a single &quot;make&quot; command (DB init, migration, seed, server, client, tunnelling, etc), so a candidate can get started on coding within 2 minutes of accepting the invite. Candidates code on Codespaces (browser-based VSCode IDE), but can choose to set up locally, though we don't guarantee there won't be package versioning conflicts or environment problems. Candidates are given a set of specs and Figma mockups (if it's a frontend/fullstack interview) and asked to build out a real feature on top of this existing codebase. When candidates submit their solution, it's in the form of a Github pull request. The experience is meant to feel the same as building a feature on the job. Right now, we support a couple of popular stacks: Node + Express, React, GraphQL, Golang, Ruby on Rails, Python/Django and Flask, and Bootstrap, and we’re growing stack support by popular demand.<p>We then take that PR, run a bunch of automated analysis on it, and produce a report for the employer. Of course there’s a limit to what an automated analysis can reveal, but standardized metrics are useful. Metrics we collect include linter output, integration testing, visual regression testing, performance (using load testing), cyclomatic/halstead complexity, identifier naming convention testing, event logs, edge case handling, code coverage. And of course all our interview projects come with automated tests that run automatically to verify the correctness of the candidate’s code (as much as unit and integration tests can do, at least—we’re not into formal verification at this stage!)<p>Right now, Litebulb compiles the report, but we're building a way for employers to do it themselves using the data collected. Litebulb is still early, so we're still manually verifying all results (24 hour turnaround policy).<p>There are a lot of interview service providers and automated screening platforms, but they tend to either not be automated (i.e. you still need engineers to do the interviews) or are early-funnel, meaning they test for basic programming or brainteasers, but not regular dev work. Litebulb is different because we're late-funnel <i>and</i> automated. We can get the depth of a service like Karat but at the scale and price point of a tool like HackerRank. Longer term, we're hoping to become something like Webflow for interviews.<p>Here's a Loom demo: <a href=\"https://www.loom.com/share/bdca5f77379140ecb69f7c1917663ae5\" rel=\"nofollow\">https://www.loom.com/share/bdca5f77379140ecb69f7c1917663ae5</a>, it's a bit informal but gets the idea across. There’s a trial mode too, for which you can sign up here: <a href=\"https://litebulb.typeform.com/to/J7mQ5KZI\" rel=\"nofollow\">https://litebulb.typeform.com/to/J7mQ5KZI</a>. Be warned that it’s still unpolished—we're probably going to still be in beta for another 3 months at least. That said, the product is usable and people have been paying and getting substantial value out of it, which is why we thought an HN launch might be a good idea.<p>We’re always looking for feedback on your interview experiences or ideas for building better tech interviews. If you have thoughts, want to try out Litebulb, or just want to chat, you can always reach me directly at gary@litebulb.io.<p>Thanks everyone!",
  "keywords": [],
  "author": {
    "@type": "Person",
    "name": "garyjlin",
    "url": "https://news.ycombinator.com/user?id=garyjlin"
  },
  "discussionUrl": "https://news.ycombinator.com/item?id=30591874",
  "sameAs": "https://www.litebulb.io",
  "dateCreated": "2022-03-07T19:09:49.394Z",
  "datePublished": "2022-03-07T19:00:34.000Z",
  "dateModified": "2022-03-07T19:09:49.394Z",
  "interactionStatistic": [
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "LikeAction"
      },
      "userInteractionCount": 8
    },
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "CommentAction"
      },
      "userInteractionCount": 0
    }
  ],
  "headline_zh-Hans": "启动HN：Litebulb（YC W22）--技术面试的自动化",
  "headline_zh-Hant": "啟動HN：Litebulb（YC W22）--技術面試的自動化",
  "@context": [
    "https://schema.org",
    {
      "@vocab": "http://schema.org/",
      "@language": "en",
      "headline_zh-Hans": {
        "@id": "headline",
        "@language": "zh-Hans"
      },
      "headline_zh-Hant": {
        "@id": "headline",
        "@language": "zh-Hant"
      },
      "@version": 1.1,
      "description_zh-Hans": {
        "@id": "description",
        "@language": "zh-Hans"
      },
      "description_zh-Hant": {
        "@id": "description",
        "@language": "zh-Hant"
      }
    }
  ],
  "description_zh-Hans": "嗨，HN，我是Litebulb（<a href=\"https://litebulb.io\" rel=\"nofollow\">https://litebulb.io</a>）的Gary。我们为远程团队实现技术现场面试的自动化。当我说 \"自动化 \"时，我应该加上 \"尽可能多\"。我们的软件并不决定你应该雇用谁! 但是我们为面试设置了开发环境，在真实的代码库上提出问题，跟踪候选人，运行测试以验证正确性，并分析提交的代码。<p>我曾在11家公司担任软件工程师，经历了超过100个面试漏斗。技术面试很糟糕。工程师磨了几个月的LeetCode，就是为了能在15分钟内写出最佳的quicksort解决方案，但在工作中，你只是从一些库中导入，就像你应该做的那样。我和我的朋友们记住了一半的HackerRank，只是为了堆积工作机会，但这些招聘团队实际上都不知道我们是否适合这些角色。在某些情况下，我们并不适合。<p>在我走到面试桌的另一边后，情况变得更糟。创建一个好的面试需要几天的时间，而工程师们讨厌为他们可能再也见不到的人进行重复的、数小时的面试。他们被从开发工作中拉出来做面试，然后不得不与团队的其他成员同步，以决定每个人的想法，并做出一个往往是武断的决定。在某些时候，人力资源部门会回来要求他们修改或升级一个两年前的面试问题，但没有人愿意或有时间这样做。在与数百名招聘经理、工程部副总裁、人力资源部门负责人和首席技术官交谈后，我知道这个问题有多普遍。我们不做LeetCod，我们的面试就像普通的开发工作。候选人可以访问Github上现有的代码库，包括数据库、服务器和客户端。环境是Docker化的，每个面试的设置都被归结为一个单一的&quot;make&quot;命令（数据库启动、迁移、种子、服务器、客户端、隧道等），所以候选人可以在接受邀请后2分钟内开始编码。候选人在Codespaces（基于浏览器的VSCode IDE）上进行编码，但也可以选择在本地设置，不过我们不保证不会出现包的版本冲突或环境问题。候选人会得到一套规格和Figma模型（如果是前端/全栈面试），并被要求在这个现有代码库的基础上建立一个真正的功能。当候选人提交他们的解决方案时，是以Github pull request的形式。这种体验的目的是要让人感觉与在工作中构建一个功能一样。现在，我们支持几个流行的堆栈。Node + Express、React、GraphQL、Golang、Ruby on Rails、Python/Django和Flask以及Bootstrap，而且我们正在根据大众的需求增加对堆栈的支持。<p>然后我们将该PR，对其运行一系列自动化分析，并为雇主制作一份报告。当然，自动分析所能揭示的内容是有限的，但标准化的指标是有用的。我们收集的指标包括linter输出、集成测试、可视化回归测试、性能（使用负载测试）、cyclomatic/halstead复杂性、标识符命名规则测试、事件日志、边缘案例处理、代码覆盖率。当然，我们所有的面试项目都有自动测试，自动运行以验证候选人代码的正确性（至少单元和集成测试可以做到这一点--我们在这个阶段还没有进入正式的验证！）<p>现在，Litebulb编译报告，但我们正在建立一种方法，让雇主使用收集的数据自己做。<p>现在有很多面试服务提供商和自动筛选平台，但它们往往不是自动化的（即你仍然需要工程师来做面试），或者是早期的漏斗，意味着它们测试基本的编程或脑筋急转弯，但不是常规的开发工作。Litebulb是不同的，因为我们是后期漏斗<i>和</i>自动化。我们可以获得像Karat这样的服务的深度，但又有像HackerRank这样的工具的规模和价位。从长远来看，我们希望成为类似Webflow的采访工具。<p>这里有一个Loom演示。<a href=\"https://www.loom.com/share/bdca5f77379140ecb69f7c1917663ae5\" rel=\"nofollow\">https://www.loom.com/share/bdca5f77379140ecb69f7c1917663ae5</a>, it's a bit informal but gets the idea across. There’s a trial mode too, for which you can sign up here: <a href=\"https://litebulb.typeform.com/to/J7mQ5KZI\" rel=\"nofollow\">https://litebulb.typeform.com/to/J7mQ5KZI</a>. Be warned that it’s still unpolished—we're probably going to still be in beta for another 3 months at least. That said, the product is usable and people have been paying and getting substantial value out of it, which is why we thought an HN launch might be a good idea.<p>We’re always look",
  "description_zh-Hant": "嗨，HN，我是Litebulb（<a href=\"https://litebulb.io\" rel=\"nofollow\">https://litebulb.io</a>）的Gary。我們為遠程團隊實現技術現場面試的自動化。當我說 \"自動化 \"時，我應該加上 \"儘可能多\"。我們的軟件並不決定你應該僱用誰! 但是我們為面試設置了開發環境，在真實的代碼庫上提出問題，跟蹤候選人，運行測試以驗證正確性，並分析提交的代碼。<p>我曾在11家公司擔任軟件工程師，經歷了超過100個面試漏斗。技術面試很糟糕。工程師磨了幾個月的LeetCode，就是為了能在15分鐘內寫出最佳的quicksort解決方案，但在工作中，你只是從一些庫中導入，就像你應該做的那樣。我和我的朋友們記住了一半的HackerRank，只是為了堆積工作機會，但這些招聘團隊實際上都不知道我們是否適合這些角色。在某些情況下，我們並不適合。<p>在我走到面試桌的另一邊後，情況變得更糟。創建一個好的面試需要幾天的時間，而工程師們討厭為他們可能再也見不到的人進行重複的、數小時的面試。他們被從開發工作中拉出來做面試，然後不得不與團隊的其他成員同步，以決定每個人的想法，並做出一個往往是武斷的決定。在某些時候，人力資源部門會回來要求他們修改或升級一個兩年前的面試問題，但沒有人願意或有時間這樣做。在與數百名招聘經理、工程部副總裁、人力資源部門負責人和首席技術官交談後，我知道這個問題有多普遍。我們不做LeetCod，我們的面試就像普通的開發工作。候選人可以訪問Github上現有的代碼庫，包括數據庫、服務器和客戶端。環境是Docker化的，每個面試的設置都被歸結為一個單一的&quot;make&quot;命令（數據庫啟動、遷移、種子、服務器、客戶端、隧道等），所以候選人可以在接受邀請後2分鐘內開始編碼。候選人在Codespaces（基於瀏覽器的VSCode IDE）上進行編碼，但也可以選擇在本地設置，不過我們不保證不會出現包的版本衝突或環境問題。候選人會得到一套規格和Figma模型（如果是前端/全棧面試），並被要求在這個現有代碼庫的基礎上建立一個真正的功能。當候選人提交他們的解決方案時，是以Github pull request的形式。這種體驗的目的是要讓人感覺與在工作中構建一個功能一樣。現在，我們支持幾個流行的堆棧。Node + Express、React、GraphQL、Golang、Ruby on Rails、Python/Django和Flask以及Bootstrap，而且我們正在根據大眾的需求增加對堆棧的支持。<p>然後我們將該PR，對其運行一系列自動化分析，併為僱主製作一份報告。當然，自動分析所能揭示的內容是有限的，但標準化的指標是有用的。我們收集的指標包括linter輸出、集成測試、可視化迴歸測試、性能（使用負載測試）、cyclomatic/halstead複雜性、標識符命名規則測試、事件日誌、邊緣案例處理、代碼覆蓋率。當然，我們所有的面試項目都有自動測試，自動運行以驗證候選人代碼的正確性（至少單元和集成測試可以做到這一點--我們在這個階段還沒有進入正式的驗證！）<p>現在，Litebulb編譯報告，但我們正在建立一種方法，讓僱主使用收集的數據自己做。<p>現在有很多面試服務提供商和自動篩選平臺，但它們往往不是自動化的（即你仍然需要工程師來做面試），或者是早期的漏斗，意味著它們測試基本的編程或腦筋急轉彎，但不是常規的開發工作。Litebulb是不同的，因為我們是後期漏斗<i>和</i>自動化。我們可以獲得像Karat這樣的服務的深度，但又有像HackerRank這樣的工具的規模和價位。從長遠來看，我們希望成為類似Webflow的採訪工具。<p>這裡有一個Loom演示。<a href=\"https://www.loom.com/share/bdca5f77379140ecb69f7c1917663ae5\" rel=\"nofollow\">https://www.loom.com/share/bdca5f77379140ecb69f7c1917663ae5</a>, it's a bit informal but gets the idea across. There’s a trial mode too, for which you can sign up here: <a href=\"https://litebulb.typeform.com/to/J7mQ5KZI\" rel=\"nofollow\">https://litebulb.typeform.com/to/J7mQ5KZI</a>. Be warned that it’s still unpolished—we're probably going to still be in beta for another 3 months at least. That said, the product is usable and people have been paying and getting substantial value out of it, which is why we thought an HN launch might be a good idea.<p>We’re always look"
}