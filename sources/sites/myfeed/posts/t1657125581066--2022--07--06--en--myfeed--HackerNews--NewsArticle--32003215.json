{
  "@type": "NewsArticle",
  "identifier": "2022--07--06--en--myfeed--HackerNews--NewsArticle--32003215",
  "url": "https://news.ycombinator.com/item?id=32003215",
  "headline": "Launch HN: Hello (YC S22) – A search engine for developers",
  "publisher": {
    "@type": "Organization",
    "name": "HackerNews",
    "url": "https://news.ycombinator.com",
    "logo": "https://hn.buzzing.cc/avatar.png"
  },
  "description": "Hi HN, we’re Michael and Justin from Hello Cognition (<a href=\"https://beta.sayhello.so\" rel=\"nofollow\">https://beta.sayhello.so</a>). We're building a better search engine for software developers. Hello saves you time by synthesizing clear explanations to technical questions along with code snippets from the web, showing them right on the search page.<p>We’ve found that most technical searches fall into a few categories: ad-hoc how-tos, understanding an API, recalling forgotten details, research, or troubleshooting. Google is too broad and shallow of a search tool to be good at this. Even after sifting through the deluge of spammy, irrelevant sites pumped full of SEO, you still have to manually find your answer through discussion boards or documentation. Their “featured snippet” approach works for simple factoid queries but quickly falls apart if a question requires reasoning about information across multiple webpages.<p>Our approach is narrow and deep — to retrieve detailed information for topics relevant to developers. When you submit a query, we pull raw site data from Bing, rerank them, and extract understanding and code snippets with our proprietary large language models. We use seq-to-seq transformer models to generate a final explanation from all of this input.<p>For our honors theses at UT Austin, we researched prototypes of large generative language models that can answer complex questions by combining information from multiple sources. We found that GPT-3, GPT-Neo/J/X, and similar autoregressive language models that predict text from left to right are prone to “hallucinating” and generating text inconsistent with the “ground truth” document. Training a sequence-to-sequence language model (T5 derivative) on our custom dataset designed for factual generation yielded much better results with less hallucination.<p>After creating this prototype, we started actively developing Hello with the idea that searching should be just like talking to a smart friend. We want to build an engine that explains complex topics clearly and concisely, and lets users ask follow-up questions using the context of their previous searches.<p>For example, when asked “what type of semaphore can function as a mutex?”, Hello pulls in the raw text from all five search results linked on the search page to generate: “A binary semaphore can be used as a mutex. Mutexes and semaphores are two different types of synchronization mechanisms. A mutex is a lock that prevents two threads from accessing the same resource at the same time. A semaphore is used to signal that a resource has become available.” We're biased, of course, but we think that the ability to reason abstractly about information from multiple web pages is a cool thing in a search engine!<p>We use BERT-based models to extract and rank code snippets if relevant to the query. Our search engine currently does well at answering applicable how-to questions such as “Sort a list of tuples by the second element”, “Set a response cookie in FastAPI”, “Get value of input in React”, “How to implement Dijkstra's algorithm.” Exclusively using our own models has also freed us from dependence on OpenAI.<p>Hello is and will always be free for individual devs. We haven’t rolled out any paid plans yet, but we’re planning to charge teams per user/month to use on internal data scattered around in wikis, documentation, slack, and emails.<p>We started Hello Cognition to scratch our own itch, but now we hope to improve the state of information retrieval for the greater developer community. If you'd like to be part of our product feedback and iteration process, we'd love to have you—please contact us at founders@sayhello.so.<p>We're looking forward to hearing your ideas, feedback, comments, and what would be helpful for you when navigating technical problems!",
  "keywords": [],
  "author": {
    "@type": "Person",
    "name": "wayy",
    "url": "https://news.ycombinator.com/user?id=wayy"
  },
  "discussionUrl": "https://news.ycombinator.com/item?id=32003215",
  "sameAs": "https://news.ycombinator.com/item?id=32003215",
  "dateCreated": "2022-07-06T16:39:41.066Z",
  "datePublished": "2022-07-06T16:24:30.000Z",
  "dateModified": "2022-07-06T16:39:41.066Z",
  "interactionStatistic": [
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "LikeAction"
      },
      "userInteractionCount": 14
    },
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "CommentAction"
      },
      "userInteractionCount": 1
    }
  ],
  "headline_zh-Hans": "启动HN：Hello (YC S22) - 一个面向开发者的搜索引擎\n",
  "headline_zh-Hant": "啟動HN：Hello (YC S22) - 一個面向開發者的搜索引擎\n",
  "@context": [
    "https://schema.org",
    {
      "@vocab": "http://schema.org/",
      "@language": "en",
      "headline_zh-Hans": {
        "@id": "headline",
        "@language": "zh-Hans"
      },
      "headline_zh-Hant": {
        "@id": "headline",
        "@language": "zh-Hant"
      },
      "@version": 1.1,
      "description_zh-Hans": {
        "@id": "description",
        "@language": "zh-Hans"
      },
      "description_zh-Hant": {
        "@id": "description",
        "@language": "zh-Hant"
      }
    }
  ],
  "description_zh-Hans": "嗨，HN，我们是来自Hello Cognition（<a href=\"https://beta.sayhello.so\" rel=\"nofollow\">https://beta.sayhello.so</a>）的迈克尔和贾斯汀。我们正在为软件开发人员建立一个更好的搜索引擎。Hello通过综合对技术问题的清晰解释以及来自网络的代码片段来节省您的时间，并将其直接显示在搜索页面上。<p>我们发现，大多数技术搜索可分为几类：临时性的操作方法、理解API、回忆被遗忘的细节、研究或故障排除。谷歌是一个过于广泛和浅薄的搜索工具，在这方面做得很好。即使在筛选了大量充满SEO的垃圾、不相关的网站之后，你仍然必须通过讨论区或文档手动找到你的答案。他们的 \"特色片段 \"方法适用于简单的事实性查询，但如果一个问题需要对多个网页的信息进行推理，则很快就会崩溃。<p>我们的方法是狭义和深入的--检索与开发人员有关的主题的详细信息。当你提交查询时，我们从Bing中提取原始网站数据，对它们进行重新排序，并利用我们专有的大型语言模型提取理解和代码片段。我们使用seq-to-seq转化器模型从所有这些输入中生成最终的解释。<p>在UT Austin的荣誉论文中，我们研究了大型生成语言模型的原型，这些模型可以通过结合多个来源的信息来回答复杂问题。我们发现，GPT-3、GPT-Neo/J/X以及类似的自回归语言模型从左到右预测文本，容易产生 \"幻觉\"，生成与 \"地面真相 \"文件不一致的文本。在我们为事实生成而设计的定制数据集上训练一个序列到序列的语言模型（T5派生），产生了更好的结果，幻觉更少。<p>在创建这个原型之后，我们开始积极开发Hello，其想法是搜索应该就像与一个聪明的朋友交谈一样。我们希望建立一个引擎，能够清晰简洁地解释复杂的主题，并让用户利用之前搜索的上下文提出后续问题。<p>例如，当被问及 \"什么类型的信号器可以作为一个突变体发挥作用？\"时，Hello从搜索页面上链接的所有五个搜索结果中提取原始文本来生成。\"一个二进制信号灯可以作为一个互斥器使用。Mutex和semaphores是两种不同类型的同步机制。一个mutex是一个锁，可以防止两个线程同时访问同一个资源。信号灯用于发出信号，表明资源已经可用\"。当然，我们是有偏见的，但我们认为，对来自多个网页的信息进行抽象推理的能力在搜索引擎中是一件很酷的事情！<p>如果与查询相关，我们使用基于BERT的模型来提取和排列代码片段。我们的搜索引擎目前在回答适用的操作问题方面做得很好，如 \"按第二个元素对一个图元列表进行排序\"、\"在FastAPI中设置一个响应cookie\"、\"在React中获取输入值\"、\"如何实现Dijkstra算法\"。完全使用我们自己的模型也使我们摆脱了对OpenAI的依赖。<p>Hello现在和将来都是对个人开发者免费。我们还没有推出任何付费计划，但我们计划按用户/月向团队收费，以用于分散在维基、文档、Slack和电子邮件中的内部数据。<p>我们启动Hello Cognition是为了满足我们自己的需求，但现在我们希望为更多的开发者社区改善信息检索的状况。如果你想成为我们产品反馈和迭代过程的一部分，我们非常欢迎你--请通过 founders@sayhello.so 与我们联系。<p>我们期待着听到你的想法、反馈、评论，以及在解决技术问题时对你有帮助的内容\n",
  "description_zh-Hant": "嗨，HN，我們是來自Hello Cognition（<a href=\"https://beta.sayhello.so\" rel=\"nofollow\">https://beta.sayhello.so</a>）的邁克爾和賈斯汀。我們正在為軟件開發人員建立一個更好的搜索引擎。Hello通過綜合對技術問題的清晰解釋以及來自網絡的代碼片段來節省您的時間，並將其直接顯示在搜索頁面上。<p>我們發現，大多數技術搜索可分為幾類：臨時性的操作方法、理解API、回憶被遺忘的細節、研究或故障排除。谷歌是一個過於廣泛和淺薄的搜索工具，在這方面做得很好。即使在篩選了大量充滿SEO的垃圾、不相關的網站之後，你仍然必須通過討論區或文檔手動找到你的答案。他們的 \"特色片段 \"方法適用於簡單的事實性查詢，但如果一個問題需要對多個網頁的信息進行推理，則很快就會崩潰。<p>我們的方法是狹義和深入的--檢索與開發人員有關的主題的詳細信息。當你提交查詢時，我們從Bing中提取原始網站數據，對它們進行重新排序，並利用我們專有的大型語言模型提取理解和代碼片段。我們使用seq-to-seq轉化器模型從所有這些輸入中生成最終的解釋。<p>在UT Austin的榮譽論文中，我們研究了大型生成語言模型的原型，這些模型可以通過結合多個來源的信息來回答覆雜問題。我們發現，GPT-3、GPT-Neo/J/X以及類似的自迴歸語言模型從左到右預測文本，容易產生 \"幻覺\"，生成與 \"地面真相 \"文件不一致的文本。在我們為事實生成而設計的定製數據集上訓練一個序列到序列的語言模型（T5派生），產生了更好的結果，幻覺更少。<p>在創建這個原型之後，我們開始積極開發Hello，其想法是搜索應該就像與一個聰明的朋友交談一樣。我們希望建立一個引擎，能夠清晰簡潔地解釋複雜的主題，並讓用戶利用之前搜索的上下文提出後續問題。<p>例如，當被問及 \"什麼類型的信號器可以作為一個突變體發揮作用？\"時，Hello從搜索頁面上鍊接的所有五個搜索結果中提取原始文本來生成。\"一個二進制信號燈可以作為一個互斥器使用。Mutex和semaphores是兩種不同類型的同步機制。一個mutex是一個鎖，可以防止兩個線程同時訪問同一個資源。信號燈用於發出信號，表明資源已經可用\"。當然，我們是有偏見的，但我們認為，對來自多個網頁的信息進行抽象推理的能力在搜索引擎中是一件很酷的事情！<p>如果與查詢相關，我們使用基於BERT的模型來提取和排列代碼片段。我們的搜索引擎目前在回答適用的操作問題方面做得很好，如 \"按第二個元素對一個圖元列表進行排序\"、\"在FastAPI中設置一個響應cookie\"、\"在React中獲取輸入值\"、\"如何實現Dijkstra算法\"。完全使用我們自己的模型也使我們擺脫了對OpenAI的依賴。<p>Hello現在和將來都是對個人開發者免費。我們還沒有推出任何付費計劃，但我們計劃按用戶/月向團隊收費，以用於分散在維基、文檔、Slack和電子郵件中的內部數據。<p>我們啟動Hello Cognition是為了滿足我們自己的需求，但現在我們希望為更多的開發者社區改善信息檢索的狀況。如果你想成為我們產品反饋和迭代過程的一部分，我們非常歡迎你--請通過 founders@sayhello.so 與我們聯繫。<p>我們期待著聽到你的想法、反饋、評論，以及在解決技術問題時對你有幫助的內容\n"
}