{
  "@type": "NewsArticle",
  "identifier": "2022--06--21--en--myfeed--HackerNews--NewsArticle--31825473",
  "url": "https://news.ycombinator.com/item?id=31825473",
  "headline": "Launch HN: Dioptra (YC W22) – Improve ML models by improving their training data",
  "publisher": {
    "@type": "Organization",
    "name": "HackerNews",
    "url": "https://news.ycombinator.com",
    "logo": "https://hn.buzzing.cc/avatar.png"
  },
  "description": "Hi HN, I’m Farah from <a href=\"https://dioptra.ai\" rel=\"nofollow\">https://dioptra.ai</a>. Dioptra tracks ML metrics to identify model error patterns and suggest the best data curation strategy to fix them.<p>We’ve seen a shift in paradigm in recent years in ML: the “code” has become a commodity: many powerful ML models are open source today. The real challenge is to grow and curate quality data. This raises the need for new data centric tools: IDEs, debuggers, monitoring. Dioptra is a data centric tool that helps debug models and fix them by systematically curating and growing the best data, at scale.<p>We experienced this problem, first hand, deploying and retraining models. Once a model was in production, maintenance was a huge pain. First, it was hard to assess model performance. Accessing the right production data to diagnose was complicated. We had to build custom scripts to connect to DBs, download production data (Compliance, look the other way!) and analyze it.<p>Second, it was hard to translate the diagnosis into concrete next steps: find the best data to fix and retrain my model. It required another set of scripts to sample new data, label it and retrain. With a large enough labeling budget, we were able to improve our models, but it wasn’t optimal: labeling is expensive, random data sampling doesn’t yield the best results ! And since the process relied on our individual domain expertise (aka gut feelings) it was inconsistent from one data scientist to the next and not scalable.<p>We talked to a couple hundred ML practitioners who helped us validate and refine our thinking (we thank every single one of them!). For example, one NLP team had to read more than 10 long legal contracts per week per person. The goal was to track any model errors. Once a month, they synthesized an Excel sheet to detect patterns of errors. Once detected, they had to read more contracts to build their retraining dataset! There were multiple issues with that process. First, the assessment of errors was subjective since it depended on individual interpretations of the legal language. Second, the sourcing of retraining data was time consuming and anecdotal. Finally, they had to spend a lot of time coaching new members to minimize subjectivity.<p>Processes like this highlight how model improvement needs to be less anecdotal and more systematic. A related problem is lack of tooling, which puts a huge strain on ML teams that are constantly asked to innovate and take on new projects.<p>Dioptra computes a comprehensive set of metrics to give ML teams a full view of their model and detect failure modes. Teams can objectively prioritize their efforts based on the impact of each error pattern. They can also slice and dice to root-cause errors, zero in on faulty data, and visualize it. What used to take days of reading can now be done in a couple hours. Teams can then quality check and curate the best data for retraining using our embedding similarity search or active learning techniques. They can easily understand, customize and systematically engineer their data curation strategy with our automation APIs in order to get the best model at each iteration and stay on top of the latest production patterns. Additionally, Dioptra fits within any ML stack. We have native integrations with major deep learning frameworks.<p>Some of our customers reduced their data ops costs by 30%. Others improved their model accuracy by 20% in one retraining cycle thanks to Dioptra.<p>Active Learning, which has been around for a while but was sort of confidential until recently, makes intentional retraining possible. This approach has been validated by ML organizations like Tesla, Cruise and Waymo. Recently, other companies like Pinterest started building similar infrastructure. However it is costly to build and requires specialized skills. We want to make it accessible to everybody.<p>We created an interactive demo for HN: <a href=\"https://capture.navattic.com/cl4hciffr2881909mv2qrlsc9g\" rel=\"nofollow\">https://capture.navattic.com/cl4hciffr2881909mv2qrlsc9g</a><p>Please share any feedback &amp; thoughts. \nThanks for reading !",
  "keywords": [],
  "author": {
    "@type": "Person",
    "name": "farahg",
    "url": "https://news.ycombinator.com/user?id=farahg"
  },
  "discussionUrl": "https://news.ycombinator.com/item?id=31825473",
  "sameAs": "https://news.ycombinator.com/item?id=31825473",
  "dateCreated": "2022-06-21T16:42:13.871Z",
  "datePublished": "2022-06-21T16:00:26.000Z",
  "dateModified": "2022-06-21T16:42:13.871Z",
  "interactionStatistic": [
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "LikeAction"
      },
      "userInteractionCount": 10
    },
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "CommentAction"
      },
      "userInteractionCount": 1
    }
  ],
  "headline_zh-Hans": "启动HN：Dioptra（YC W22）--通过改善训练数据来改进ML模型\n",
  "headline_zh-Hant": "啟動HN：Dioptra（YC W22）--通過改善訓練數據來改進ML模型\n",
  "@context": [
    "https://schema.org",
    {
      "@vocab": "http://schema.org/",
      "@language": "en",
      "headline_zh-Hans": {
        "@id": "headline",
        "@language": "zh-Hans"
      },
      "headline_zh-Hant": {
        "@id": "headline",
        "@language": "zh-Hant"
      },
      "@version": 1.1,
      "description_zh-Hans": {
        "@id": "description",
        "@language": "zh-Hans"
      },
      "description_zh-Hant": {
        "@id": "description",
        "@language": "zh-Hant"
      }
    }
  ],
  "description_zh-Hans": "Hi HN，我是来自<a href=\"https://dioptra.ai\" rel=\"nofollow\">https://dioptra.ai</a>的Farah。Dioptra跟踪ML指标，以确定模型的错误模式，并建议最佳的数据策划策略来修复它们。<p>近年来，我们看到ML的范式发生了变化：\"代码 \"已经成为一种商品：许多强大的ML模型如今都是开源的。真正的挑战是如何增长和策划高质量的数据。这就提出了对以数据为中心的新工具的需求。集成开发环境、调试器、监控。Dioptra是一个以数据为中心的工具，帮助调试模型，并通过系统地策划和增长最好的数据来修复它们。<p>我们在部署和重新训练模型时亲身经历了这个问题。一旦模型进入生产阶段，维护工作就是一个巨大的痛苦。首先，很难评估模型的性能。访问正确的生产数据来进行诊断是很复杂的。我们不得不建立自定义脚本来连接数据库，下载生产数据（遵从，看另一边！）并对其进行分析。<p>其次，很难将诊断结果转化为具体的下一步行动：找到最佳数据来修复和重新训练我的模型。这需要另一套脚本来对新数据进行采样、标注和重新训练。有了足够大的标签预算，我们能够改善我们的模型，但这并不是最理想的：标签是昂贵的，随机的数据抽样并不能产生最好的结果 ! <p>我们与几百名ML从业者交谈过，他们帮助我们验证和完善了我们的想法（我们感谢他们中的每一个人！）。例如，一个NLP团队不得不每周每人阅读超过10份长的法律合同。目标是跟踪任何模型错误。每月一次，他们综合了Excel表格，以检测错误的模式。一旦发现，他们必须阅读更多的合同，以建立他们的再培训数据集。这个过程有多个问题。首先，对错误的评估是主观的，因为它取决于个人对法律语言的解释。其次，再培训数据的来源很耗时，而且是传闻。最后，他们不得不花大量时间辅导新成员，以尽量减少主观性。<p>像这样的过程突出了模型的改进需要减少传闻，更系统化。一个相关的问题是缺乏工具，这给不断被要求创新和承担新项目的ML团队带来了巨大的压力。<p>Dioptra计算了一套全面的指标，让ML团队全面了解他们的模型并检测失败模式。团队可以根据每个错误模式的影响，客观地确定其工作的优先次序。他们还可以对错误的根源进行切片和切块，将有问题的数据归零，并将其可视化。过去需要几天的阅读，现在可以在几个小时内完成。然后，团队可以使用我们的嵌入相似性搜索或主动学习技术进行质量检查和策划最佳数据的再培训。他们可以通过我们的自动化API轻松地理解、定制和系统地设计他们的数据策划策略，以便在每次迭代中获得最佳模型，并保持在最新的生产模式之上。此外，Dioptra适合任何ML栈。我们与主要的深度学习框架进行了原生集成。<p>我们的一些客户将其数据运营成本降低了30%。<p>主动学习（Active Learning）已经存在了一段时间，但直到最近才成为一种机密，它使有意的再训练成为可能。这种方法已经被特斯拉、Cruise和Waymo等ML组织所验证。Recently, other companies like Pinterest started building similar infrastructure. However it is costly to build and requires specialized skills. We want to make it accessible to everybody.<p>We created an interactive demo for HN: <a href=\"https://capture.navattic.com/cl4hciffr2881909mv2qrlsc9g\" rel=\"nofollow\">https://capture.navattic.com/cl4hciffr2881909mv2qrlsc9g</a><p>Please share any feedback &amp; thoughts. \nThanks for reading !\n",
  "description_zh-Hant": "Hi HN，我是來自<a href=\"https://dioptra.ai\" rel=\"nofollow\">https://dioptra.ai</a>的Farah。Dioptra跟蹤ML指標，以確定模型的錯誤模式，並建議最佳的數據策劃策略來修復它們。<p>近年來，我們看到ML的範式發生了變化：\"代碼 \"已經成為一種商品：許多強大的ML模型如今都是開源的。真正的挑戰是如何增長和策劃高質量的數據。這就提出了對以數據為中心的新工具的需求。集成開發環境、調試器、監控。Dioptra是一個以數據為中心的工具，幫助調試模型，並通過系統地策劃和增長最好的數據來修復它們。<p>我們在部署和重新訓練模型時親身經歷了這個問題。一旦模型進入生產階段，維護工作就是一個巨大的痛苦。首先，很難評估模型的性能。訪問正確的生產數據來進行診斷是很複雜的。我們不得不建立自定義腳本來連接數據庫，下載生產數據（遵從，看另一邊！）並對其進行分析。<p>其次，很難將診斷結果轉化為具體的下一步行動：找到最佳數據來修復和重新訓練我的模型。這需要另一套腳本來對新數據進行採樣、標註和重新訓練。有了足夠大的標籤預算，我們能夠改善我們的模型，但這並不是最理想的：標籤是昂貴的，隨機的數據抽樣並不能產生最好的結果 ! <p>我們與幾百名ML從業者交談過，他們幫助我們驗證和完善了我們的想法（我們感謝他們中的每一個人！）。例如，一個NLP團隊不得不每週每人閱讀超過10份長的法律合同。目標是跟蹤任何模型錯誤。每月一次，他們綜合了Excel表格，以檢測錯誤的模式。一旦發現，他們必須閱讀更多的合同，以建立他們的再培訓數據集。這個過程有多個問題。首先，對錯誤的評估是主觀的，因為它取決於個人對法律語言的解釋。其次，再培訓數據的來源很耗時，而且是傳聞。最後，他們不得不花大量時間輔導新成員，以儘量減少主觀性。<p>像這樣的過程突出了模型的改進需要減少傳聞，更系統化。一個相關的問題是缺乏工具，這給不斷被要求創新和承擔新項目的ML團隊帶來了巨大的壓力。<p>Dioptra計算了一套全面的指標，讓ML團隊全面瞭解他們的模型並檢測失敗模式。團隊可以根據每個錯誤模式的影響，客觀地確定其工作的優先次序。他們還可以對錯誤的根源進行切片和切塊，將有問題的數據歸零，並將其可視化。過去需要幾天的閱讀，現在可以在幾個小時內完成。然後，團隊可以使用我們的嵌入相似性搜索或主動學習技術進行質量檢查和策劃最佳數據的再培訓。他們可以通過我們的自動化API輕鬆地理解、定製和系統地設計他們的數據策劃策略，以便在每次迭代中獲得最佳模型，並保持在最新的生產模式之上。此外，Dioptra適合任何ML棧。我們與主要的深度學習框架進行了原生集成。<p>我們的一些客戶將其數據運營成本降低了30%。<p>主動學習（Active Learning）已經存在了一段時間，但直到最近才成為一種機密，它使有意的再訓練成為可能。這種方法已經被特斯拉、Cruise和Waymo等ML組織所驗證。Recently, other companies like Pinterest started building similar infrastructure. However it is costly to build and requires specialized skills. We want to make it accessible to everybody.<p>We created an interactive demo for HN: <a href=\"https://capture.navattic.com/cl4hciffr2881909mv2qrlsc9g\" rel=\"nofollow\">https://capture.navattic.com/cl4hciffr2881909mv2qrlsc9g</a><p>Please share any feedback &amp; thoughts. \nThanks for reading !\n"
}