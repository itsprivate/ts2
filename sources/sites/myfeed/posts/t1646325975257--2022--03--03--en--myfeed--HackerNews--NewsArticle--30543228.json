{
  "@type": "NewsArticle",
  "identifier": "2022--03--03--en--myfeed--HackerNews--NewsArticle--30543228",
  "url": "https://news.ycombinator.com/item?id=30543228",
  "headline": "Launch HN: Slai (YC W22) – Build ML models quickly and deploy them as apps",
  "publisher": {
    "@type": "Organization",
    "name": "HackerNews",
    "url": "https://news.ycombinator.com",
    "logo": "https://hn.buzzing.cc/avatar.png"
  },
  "description": "Hi HN, we’re Eli and Luke from Slai (<a href=\"https://www.slai.io/hn/62203ae9ee716300083c879b\" rel=\"nofollow\">https://www.slai.io/hn/62203ae9ee716300083c879b</a>). Slai is a fast ML prototyping platform designed for software engineers. We make it easy to develop and train ML models, then deploy them as production-ready applications with a single link.<p>ML applications are increasingly built by software engineers rather than data scientists, but getting ML into a product is still a pain. You have to set up local environments, manage servers, build CI/CD pipelines, self-host open-source tools. Many engineers just want to leverage ML for their products without doing any of that. Slai takes care of all of it, so you can focus on your own work.<p>Slai is opinionated: we are specifically for software developers who want to build models into products. We cover the entire ML lifecycle, all the way from initial exploration and prototyping to deploying your model as a REST API. Our sandboxes contain all the code, dataset, dependencies, and application logic needed for your model to run.<p>We needed this product ourselves. A year ago, Luke was working as a robotics engineer, working on a computationally intensive problem on a robot arm (force vector estimation). He started writing an algorithm, but realized a neural network could solve the problem faster and more accurately. Many people had solved this before, so it wasn’t difficult to find an example neural net and get the model trained. You’d think that would be the hard part—but actually the hard part was getting the model available via a REST API. It didn’t seem sensible to write a  Flask app and spin up an EC2 instance just to serve up this little ML microservice. The whole thing was unnecessarily cumbersome.<p>After researching various MLOps tools, we started to notice a pattern—most are designed for data scientists doing experimentation, rather than software engineers who want to solve a specific problem using ML. We set out to build an ML tool that is designed for developers and organized around SWE best practices. That means leaving notebooks entirely behind, even though they're still the preferred form factor for data exploration and analysis. We've made the bet that a normal IDE with some &quot;Jupyter-lite&quot; functionality (e.g. splitting code into cells that can be run independently) is a fair trade-off for software engineers who want easy and fast product development.<p>Our browser-based IDE uses a project structure with five components: (1) a training section, for model training scripts, (2) a handler, for pre- and post-processing logic for the model and API schema, (3) a test file, for writing unit tests, (4) dependencies, which are interactively installed Python libraries, and (5) datasets used for model training. By modularizing the project in this way, we ensure that ML apps are functional end-to-end (if we didn't do this, you can imagine a scenario where a data scientist hands off a model to a software engineer for deployment, who's then forced to understand how to create an API around the model, and how to parse a funky ML tensor output into a JSON field). Models can be trained on CPUs or GPUs, and deployed to our fully-managed backend for invoking via a REST API.<p>Each browser-based IDE instance (“sandbox”) contains all the source code, libraries, and data needed for an ML application. When a user lands on a sandbox, we remotely spin up a Docker container and execute all runtime actions in the remote environment. When a model is deployed, we ship that container onto our inference cluster, where it’s available to call via a REST API.<p>Customers have so far used Slai to categorize bills and invoices for a fintech app; recognize gestures from MYO armband movement data; detect anomalies in electrocardiograms; and recommend content in a news feed based on previous content a user has liked/saved.<p>If you’d like to try it, here are three projects you can play with:<p><i>Convert any image into stylized art</i> - <a href=\"https://www.slai.io/hn/62203ae9ee716300083c879b\" rel=\"nofollow\">https://www.slai.io/hn/62203ae9ee716300083c879b</a><p><i>Predict Peyton Manning’s Wikipedia page views</i> - <a href=\"https://www.slai.io/hn/6215708345d19a0008be3f25\" rel=\"nofollow\">https://www.slai.io/hn/6215708345d19a0008be3f25</a><p><i>Predict how happy people are likely to be in a given country</i> - <a href=\"https://www.slai.io/hn/621e9bb3eda93f00081875fc\" rel=\"nofollow\">https://www.slai.io/hn/621e9bb3eda93f00081875fc</a><p>We don’t have great documentation yet, but here’s what to do: (1) Click “train” to train the model; (2) Click the test tube icon to try out the model - this is where you enter sentences for GPT-2 to complete, or images to transform, etc; (3) Click “test model” to run unit tests; (4) Click “package” to, er, package the model; (5) Deploy, by clicking the rocket ship icon and selecting your packaged model. “Deploy” means everything in the sandbox gets turned into a REST endpoint, for users to consume in their own apps. You can do the first 3 steps without signup and then there’s a signup dialog before step 4.<p>We make money by charging subscriptions to our tool. We also charge per compute hour for model training and inference, but (currently) that's just the wholesale cloud cost—we don't make any margin there.<p>Our intention with Slai is to allow people to build small, useful applications with ML. Do you have any ideas for an ML-powered microservice? We’d love to hear about apps you’d like to create. You can create models from scratch, or use pretrained models, so you can be really creative. Thoughts, comments, feedback welcome!",
  "keywords": [],
  "author": {
    "@type": "Person",
    "name": "Mernit",
    "url": "https://news.ycombinator.com/user?id=Mernit"
  },
  "discussionUrl": "https://news.ycombinator.com/item?id=30543228",
  "sameAs": "https://news.ycombinator.com/item?id=30543228",
  "dateCreated": "2022-03-03T16:46:15.257Z",
  "datePublished": "2022-03-03T16:39:03.000Z",
  "dateModified": "2022-03-03T16:46:15.257Z",
  "interactionStatistic": [
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "LikeAction"
      },
      "userInteractionCount": 5
    },
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "CommentAction"
      },
      "userInteractionCount": 0
    }
  ],
  "headline_zh-Hans": "启动HN：Slai（YC W22）--快速构建ML模型并将其部署为应用程序",
  "headline_zh-Hant": "啟動HN：Slai（YC W22）--快速構建ML模型並將其部署為應用程序",
  "@context": [
    "https://schema.org",
    {
      "@vocab": "http://schema.org/",
      "@language": "en",
      "headline_zh-Hans": {
        "@id": "headline",
        "@language": "zh-Hans"
      },
      "headline_zh-Hant": {
        "@id": "headline",
        "@language": "zh-Hant"
      },
      "@version": 1.1,
      "description_zh-Hans": {
        "@id": "description",
        "@language": "zh-Hans"
      },
      "description_zh-Hant": {
        "@id": "description",
        "@language": "zh-Hant"
      }
    }
  ],
  "description_zh-Hans": "嗨，HN，我们是来自Slai（<a href=\"https://www.slai.io/hn/62203ae9ee716300083c879b\" rel=\"nofollow\">https://www.slai.io/hn/62203ae9ee716300083c879b</a>）的Eli和Luke。Slai是一个为软件工程师设计的快速ML原型平台。我们使开发和训练ML模型变得容易，然后通过一个链接将它们部署为可用于生产的应用程序。<p>ML应用程序越来越多地由软件工程师而不是数据科学家来构建，但将ML纳入产品仍然是一种痛苦。你必须建立本地环境，管理服务器，建立CI/CD管道，自我托管开源工具。许多工程师只是想在他们的产品中利用ML，而不需要做这些。Slai负责所有这些工作，所以你可以专注于自己的工作。<p>Slai是有主见的：我们专门为那些想在产品中建立模型的软件开发人员服务。我们涵盖了整个ML生命周期，从最初的探索和原型设计一直到将你的模型部署为REST API。我们的沙盒包含你的模型运行所需的所有代码、数据集、依赖性和应用逻辑。一年前，Luke作为一名机器人工程师，正在研究一个机器人手臂上的计算密集型问题（力向量估计）。他开始写一个算法，但意识到一个神经网络可以更快更准确地解决这个问题。很多人以前都解决过这个问题，所以找到一个神经网络的例子并让模型得到训练并不困难。你会认为这是最困难的部分，但实际上最困难的部分是通过REST API获得模型。写一个Flask应用程序并启动一个EC2实例来提供这个小的ML微服务似乎并不明智。<p>在研究了各种MLOps工具后，我们开始注意到一种模式--大多数是为做实验的数据科学家设计的，而不是为想用ML解决具体问题的软件工程师设计的。我们着手建立一个ML工具，它是为开发人员设计的，并围绕SWE的最佳实践组织。这意味着将笔记本完全抛在后面，尽管它们仍然是数据探索和分析的首选形式因素。我们打赌，一个具有一些Jupyter-lite&quot;功能（例如，将代码分割成可以独立运行的单元）的普通IDE对于那些希望轻松、快速开发产品的软件工程师来说是一个公平的权衡。(1) 训练部分，用于模型训练脚本；(2) 处理程序，用于模型和API模式的前后处理逻辑；(3) 测试文件，用于编写单元测试；(4) 依赖项，是交互式安装的Python库；以及(5) 用于模型训练的数据集。通过以这种方式将项目模块化，我们确保ML应用是端到端的功能（如果我们不这样做，你可以想象这样的场景：数据科学家将模型交给软件工程师部署，然后他被迫了解如何围绕模型创建一个API，以及如何将一个有趣的ML张量输出解析成JSON字段）。模型可以在CPU或GPU上进行训练，并部署到我们完全管理的后端，通过REST API进行调用。<p>每个基于浏览器的IDE实例（\"沙盒\"）包含ML应用所需的所有源代码、库和数据。当用户登陆沙盒时，我们远程启动一个Docker容器，并在远程环境中执行所有运行时操作。When a model is deployed, we ship that container onto our inference cluster, where it’s available to call via a REST API.<p>Customers have so far used Slai to categorize bills and invoices for a fintech app; recognize gestures from MYO armband movement data; detect anomalies in electrocardiograms; and recommend content in a news feed based on previous content a user has liked/saved. <p>If you’d like to try it, here are three projects you can play with:<p><i>Convert any image into stylized art</i> - <a href=\"https://www.slai. io/hn/62203ae9ee716300083c879b\" rel=\"nofollow\">https://www.slai.io/hn/62203ae9ee716300083c879b</a><p><i>Predict Peyton Manning’s Wikipedia page views</i> - <a href=\"https://www.slai.io/hn/6215708345d19a0008be3f25\" rel=\"nofollow\">https://www.slai. io/hn/6215708345d19a0008be3f25</a><p><i>Predict how happy people are likely to be in a given country</i> - <a href=\"https://www.slai.io/hn/621e9bb3eda93f00081875fc\" rel=\"nofollow\">https://www.slai.io/hn/621e9bb3eda93f00081875fc</a><p>We don’t have great documentation yet, but here’s what to do: (1) 点击 \"训练 \"来训练模型；(2) 点击试管图标来试用模型--这是你输入句子来完成GPT-2，或者输入图像来转换等等；(3) 点击 \"测试模型 \"来运行单元测试；(4) 点击 \"打包 \"来，呃，打包模型；(5) 通过点击火箭船图标并选择你打包的模型来部署。\"部署 \"意味着在沙盒中的一切",
  "description_zh-Hant": "嗨，HN，我們是來自Slai（<a href=\"https://www.slai.io/hn/62203ae9ee716300083c879b\" rel=\"nofollow\">https://www.slai.io/hn/62203ae9ee716300083c879b</a>）的Eli和Luke。Slai是一個為軟件工程師設計的快速ML原型平臺。我們使開發和訓練ML模型變得容易，然後通過一個鏈接將它們部署為可用於生產的應用程序。<p>ML應用程序越來越多地由軟件工程師而不是數據科學家來構建，但將ML納入產品仍然是一種痛苦。你必須建立本地環境，管理服務器，建立CI/CD管道，自我託管開源工具。許多工程師只是想在他們的產品中利用ML，而不需要做這些。Slai負責所有這些工作，所以你可以專注於自己的工作。<p>Slai是有主見的：我們專門為那些想在產品中建立模型的軟件開發人員服務。我們涵蓋了整個ML生命週期，從最初的探索和原型設計一直到將你的模型部署為REST API。我們的沙盒包含你的模型運行所需的所有代碼、數據集、依賴性和應用邏輯。一年前，Luke作為一名機器人工程師，正在研究一個機器人手臂上的計算密集型問題（力向量估計）。他開始寫一個算法，但意識到一個神經網絡可以更快更準確地解決這個問題。很多人以前都解決過這個問題，所以找到一個神經網絡的例子並讓模型得到訓練並不困難。你會認為這是最困難的部分，但實際上最困難的部分是通過REST API獲得模型。寫一個Flask應用程序並啟動一個EC2實例來提供這個小的ML微服務似乎並不明智。<p>在研究了各種MLOps工具後，我們開始注意到一種模式--大多數是為做實驗的數據科學家設計的，而不是為想用ML解決具體問題的軟件工程師設計的。我們著手建立一個ML工具，它是為開發人員設計的，並圍繞SWE的最佳實踐組織。這意味著將筆記本完全拋在後面，儘管它們仍然是數據探索和分析的首選形式因素。我們打賭，一個具有一些Jupyter-lite&quot;功能（例如，將代碼分割成可以獨立運行的單元）的普通IDE對於那些希望輕鬆、快速開發產品的軟件工程師來說是一個公平的權衡。(1) 訓練部分，用於模型訓練腳本；(2) 處理程序，用於模型和API模式的前後處理邏輯；(3) 測試文件，用於編寫單元測試；(4) 依賴項，是交互式安裝的Python庫；以及(5) 用於模型訓練的數據集。通過以這種方式將項目模塊化，我們確保ML應用是端到端的功能（如果我們不這樣做，你可以想象這樣的場景：數據科學家將模型交給軟件工程師部署，然後他被迫瞭解如何圍繞模型創建一個API，以及如何將一個有趣的ML張量輸出解析成JSON字段）。模型可以在CPU或GPU上進行訓練，並部署到我們完全管理的後端，通過REST API進行調用。<p>每個基於瀏覽器的IDE實例（\"沙盒\"）包含ML應用所需的所有源代碼、庫和數據。當用戶登陸沙盒時，我們遠程啟動一個Docker容器，並在遠程環境中執行所有運行時操作。When a model is deployed, we ship that container onto our inference cluster, where it’s available to call via a REST API.<p>Customers have so far used Slai to categorize bills and invoices for a fintech app; recognize gestures from MYO armband movement data; detect anomalies in electrocardiograms; and recommend content in a news feed based on previous content a user has liked/saved. <p>If you’d like to try it, here are three projects you can play with:<p><i>Convert any image into stylized art</i> - <a href=\"https://www.slai. io/hn/62203ae9ee716300083c879b\" rel=\"nofollow\">https://www.slai.io/hn/62203ae9ee716300083c879b</a><p><i>Predict Peyton Manning’s Wikipedia page views</i> - <a href=\"https://www.slai.io/hn/6215708345d19a0008be3f25\" rel=\"nofollow\">https://www.slai. io/hn/6215708345d19a0008be3f25</a><p><i>Predict how happy people are likely to be in a given country</i> - <a href=\"https://www.slai.io/hn/621e9bb3eda93f00081875fc\" rel=\"nofollow\">https://www.slai.io/hn/621e9bb3eda93f00081875fc</a><p>We don’t have great documentation yet, but here’s what to do: (1) 點擊 \"訓練 \"來訓練模型；(2) 點擊試管圖標來試用模型--這是你輸入句子來完成GPT-2，或者輸入圖像來轉換等等；(3) 點擊 \"測試模型 \"來運行單元測試；(4) 點擊 \"打包 \"來，呃，打包模型；(5) 通過點擊火箭船圖標並選擇你打包的模型來部署。\"部署 \"意味著在沙盒中的一切"
}