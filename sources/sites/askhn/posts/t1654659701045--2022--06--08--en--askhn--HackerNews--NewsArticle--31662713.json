{
  "@type": "NewsArticle",
  "identifier": "2022--06--08--en--askhn--HackerNews--NewsArticle--31662713",
  "url": "https://news.ycombinator.com/item?id=31662713",
  "headline": "Ask HN: How do you automate your data analytics report?",
  "publisher": {
    "@type": "Organization",
    "name": "HackerNews",
    "url": "https://news.ycombinator.com",
    "logo": "https://hn.buzzing.cc/avatar.png"
  },
  "description": "I'm currently working on how to speed up our analytics report development workflow.<p>So imagine, you have this table called A with this structure<p>+----------+--------------+---------+----------+<p>| location |  order_count |   gmv   |  net_gmv |<p>+----------+--------------+---------+----------+<p>| TX       |         1000 |  9000.0 |   8000.0 |<p>| FL       |         1000 |  9000.0 |   8000.0 |<p>+----------+--------------+---------+----------+<p>then you want to have another table called B with this structure<p>+-------+--------------+---------+----------+<p>|  age  |  order_count |   gmv   |  net_gmv |<p>+-------+--------------+---------+----------+<p>| 20-30 |         1000 |  9000.0 |   8000.0 |<p>| 30-40 |         1000 |  9000.0 |   8000.0 |<p>| 40-50 |         1000 |  9000.0 |   8000.0 |<p>+-------+--------------+---------+----------+<p>The location and age are the dimension needed for the report, eventually we'll be having different dimension needed for our report. What we're doing now is we develop a Spark-SQL job for each table. But we think this is not gonna scale because every time we want to add new dimension, we need to develop the Spark-SQL job again (same logic but different group by dimension)<p>So I'm wondering whether there's a better way to do this. Anyone has any experience with this kind of problem before? Any pointer how to do this efficiently (I'm thinking someone could just specify the dimension they need and there'll be a script where it'll automatically generate the new table based on the specified dimension)<p>Thanks",
  "keywords": [
    "Ask HN"
  ],
  "genre": "Ask HN",
  "author": {
    "@type": "Person",
    "name": "mohon",
    "url": "https://news.ycombinator.com/user?id=mohon"
  },
  "discussionUrl": "https://news.ycombinator.com/item?id=31662713",
  "sameAs": "https://news.ycombinator.com/item?id=31662713",
  "dateCreated": "2022-06-08T03:41:41.045Z",
  "datePublished": "2022-06-08T03:05:22.000Z",
  "dateModified": "2022-06-08T03:41:41.045Z",
  "interactionStatistic": [
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "LikeAction"
      },
      "userInteractionCount": 1
    },
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "CommentAction"
      },
      "userInteractionCount": 0
    }
  ],
  "headline_zh-Hans": "Ask HN: 如何使你的数据分析报告自动化？\n",
  "headline_zh-Hant": "Ask HN: 如何使你的數據分析報告自動化？\n",
  "@context": [
    "https://schema.org",
    {
      "@vocab": "http://schema.org/",
      "@language": "en",
      "headline_zh-Hans": {
        "@id": "headline",
        "@language": "zh-Hans"
      },
      "headline_zh-Hant": {
        "@id": "headline",
        "@language": "zh-Hant"
      },
      "@version": 1.1,
      "description_zh-Hans": {
        "@id": "description",
        "@language": "zh-Hans"
      },
      "description_zh-Hant": {
        "@id": "description",
        "@language": "zh-Hant"
      }
    }
  ],
  "description_zh-Hans": "我目前正在研究如何加快我们的分析报告开发工作流程。<p>因此，想象一下，你有这个叫做A的表，有这样的结构<p>+----------+--------------+---------+----------+<p>| location | order_count | gmv | net_gmv |<p>+--------------+---------+----------+<p>| TX | 1000 | 9000.0 | 8000.0 |<p>| FL | 1000 | 9000.0 | 8000. 0 |<p>+----------+--------------+---------+----------+<p>那么你要有另一个叫做B的表，其结构如下<p>+-------+--------------+---------+----------+<p>| age | order_count | gmv | net_gmv |<p>+-------+--------------+---------+----------+<p>| 20-30 | 1000 | 9000。 0 | 8000.0 |<p>| 30-40 | 1000 | 9000.0 | 8000.0 |<p>| 40-50 | 1000 | 9000.0 | 8000.0 |<p>+-------+--------------+---------+----------+<p>地点和年龄是报告需要的维度，最终我们的报告会有不同的维度需要。我们现在所做的是为每个表开发一个Spark-SQL作业。但我们认为这不会有规模，因为每次我们想添加新的维度时，我们需要再次开发Spark-SQL作业（相同的逻辑，但不同的维度分组）<p>所以我想知道是否有更好的方法来做这个。有没有人有过处理这种问题的经验？有没有人指出如何有效地做到这一点（我想有人可以直接指定他们需要的维度，然后有一个脚本，它将根据指定的维度自动生成新的表）<p>谢谢\n",
  "description_zh-Hant": "我目前正在研究如何加快我們的分析報告開發工作流程。<p>因此，想象一下，你有這個叫做A的表，有這樣的結構<p>+----------+--------------+---------+----------+<p>| location | order_count | gmv | net_gmv |<p>+--------------+---------+----------+<p>| TX | 1000 | 9000.0 | 8000.0 |<p>| FL | 1000 | 9000.0 | 8000. 0 |<p>+----------+--------------+---------+----------+<p>那麼你要有另一個叫做B的表，其結構如下<p>+-------+--------------+---------+----------+<p>| age | order_count | gmv | net_gmv |<p>+-------+--------------+---------+----------+<p>| 20-30 | 1000 | 9000。 0 | 8000.0 |<p>| 30-40 | 1000 | 9000.0 | 8000.0 |<p>| 40-50 | 1000 | 9000.0 | 8000.0 |<p>+-------+--------------+---------+----------+<p>地點和年齡是報告需要的維度，最終我們的報告會有不同的維度需要。我們現在所做的是為每個表開發一個Spark-SQL作業。但我們認為這不會有規模，因為每次我們想添加新的維度時，我們需要再次開發Spark-SQL作業（相同的邏輯，但不同的維度分組）<p>所以我想知道是否有更好的方法來做這個。有沒有人有過處理這種問題的經驗？有沒有人指出如何有效地做到這一點（我想有人可以直接指定他們需要的維度，然後有一個腳本，它將根據指定的維度自動生成新的表）<p>謝謝\n"
}