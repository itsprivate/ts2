{
  "@type": "NewsArticle",
  "identifier": "2022--03--25--en--askhn--HackerNews--NewsArticle--30802422",
  "url": "https://news.ycombinator.com/item?id=30802422",
  "headline": "Ask HN: Should expert opinion be a bigger part of the Machine Learning world?",
  "publisher": {
    "@type": "Organization",
    "name": "HackerNews",
    "url": "https://news.ycombinator.com",
    "logo": "https://hn.buzzing.cc/avatar.png"
  },
  "description": "I came across a Twitter thread (linked in comments) which shows some interesting results when trying to recolor historical photos that have been decolored. The recolored photos are a lot drabber than the original (example in comments), and the thread author says that this gives us a skewed view of the past, making us think the past was a lot more boring than it was.<p>I thought of some related questions that I thought could be good for discussion here:<p>- Do you think that expert opinion should be consulted in the Machine Learning process more? If so, where? (perhaps omitting Expert Systems)<p>- Is there too much faith that a result from an ML model is the &quot;right&quot; result? (a phenomenon that maybe isn't specific to ML but a result of human tendencies?)<p>- Do ML practitioners have a responsibility to clearly communicate to the general public the limitations and degree-of-confidence in these systems?<p>- Am I reading too much into this, and this colorization model is just a fun model to play with, and the conclusions of the Twitter thread are too speculative or conjectural?<p>- Is this colorization issue just another form of bias that needs to be ironed out?<p>- The thread concludes by saying that colorization should be left to experts who can use context to pick accurate colors. I think this is too extreme, and that ML systems can incorporate expertise when training, or after during evaluation. Do you think there are any jobs/problems that ML methods could be applied to but should be left to experts (some considerations might be safety, privacy, ethics, etc.)<p>I know that ultimately a lot of these questions can simply boil down to statistics and their interpretation, so I'm not sure exactly where discussion could/should/will lead, but I'm looking forward to hearing your opinions!",
  "keywords": [
    "Ask HN"
  ],
  "genre": "Ask HN",
  "author": {
    "@type": "Person",
    "name": "SleekEagle",
    "url": "https://news.ycombinator.com/user?id=SleekEagle"
  },
  "discussionUrl": "https://news.ycombinator.com/item?id=30802422",
  "sameAs": "https://news.ycombinator.com/item?id=30802422",
  "dateCreated": "2022-03-25T14:28:02.159Z",
  "datePublished": "2022-03-25T14:16:11.000Z",
  "dateModified": "2022-03-25T14:28:02.159Z",
  "interactionStatistic": [
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "LikeAction"
      },
      "userInteractionCount": 1
    },
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "CommentAction"
      },
      "userInteractionCount": 1
    }
  ],
  "headline_zh-Hans": "Ask HN: 专家意见是否应该成为机器学习世界中更大的一部分？",
  "headline_zh-Hant": "Ask HN: 專家意見是否應該成為機器學習世界中更大的一部分？",
  "@context": [
    "https://schema.org",
    {
      "@vocab": "http://schema.org/",
      "@language": "en",
      "headline_zh-Hans": {
        "@id": "headline",
        "@language": "zh-Hans"
      },
      "headline_zh-Hant": {
        "@id": "headline",
        "@language": "zh-Hant"
      },
      "@version": 1.1,
      "description_zh-Hans": {
        "@id": "description",
        "@language": "zh-Hans"
      },
      "description_zh-Hant": {
        "@id": "description",
        "@language": "zh-Hant"
      }
    }
  ],
  "description_zh-Hans": "我在Twitter上看到一个帖子（链接在评论中），其中显示了一些有趣的结果，当试图给已经脱色的历史照片重新着色时。重新着色的照片比原来的照片单调很多（评论中的例子），该线程的作者说，这让我们对过去的看法有了偏差，让我们觉得过去比实际情况要无聊得多。<p>我想到了一些相关的问题，我认为可以在这里讨论：<p>- 你认为在机器学习过程中应该更多地参考专家意见吗？如果是的话，在哪里？(也许省略专家系统)<p>- 是否有太多人相信ML模型的结果是正确的？ (这种现象也许不是ML特有的，而是人类倾向的结果？)<p>- ML从业者是否有责任向公众清楚地传达这些系统的限制和信任程度？ <p>- 我是否在这方面读得太多了，这个着色模型只是一个有趣的模型，Twitter线程的结论过于推测或猜测？<p>- 这个着色问题是否只是另一种形式的偏见，需要被消除？<p>- 该线程的结论是，着色应该留给专家，他们可以利用上下文来挑选准确的颜色。我认为这太极端了，ML系统可以在训练时加入专业知识，或者在评估时加入专业知识。你认为是否有任何工作/问题可以应用ML方法，但应该留给专家处理（一些考虑因素可能是安全、隐私、道德等）<p>我知道最终这些问题很多都可以简单地归结为统计数据和它们的解释，所以我不确定讨论可以/应该/将导致什么，但我期待着听到你的意见",
  "description_zh-Hant": "我在Twitter上看到一個帖子（鏈接在評論中），其中顯示了一些有趣的結果，當試圖給已經脫色的歷史照片重新著色時。重新著色的照片比原來的照片單調很多（評論中的例子），該線程的作者說，這讓我們對過去的看法有了偏差，讓我們覺得過去比實際情況要無聊得多。<p>我想到了一些相關的問題，我認為可以在這裡討論：<p>- 你認為在機器學習過程中應該更多地參考專家意見嗎？如果是的話，在哪裡？(也許省略專家系統)<p>- 是否有太多人相信ML模型的結果是正確的？ (這種現象也許不是ML特有的，而是人類傾向的結果？)<p>- ML從業者是否有責任向公眾清楚地傳達這些系統的限制和信任程度？ <p>- 我是否在這方面讀得太多了，這個著色模型只是一個有趣的模型，Twitter線程的結論過於推測或猜測？<p>- 這個著色問題是否只是另一種形式的偏見，需要被消除？<p>- 該線程的結論是，著色應該留給專家，他們可以利用上下文來挑選準確的顏色。我認為這太極端了，ML系統可以在訓練時加入專業知識，或者在評估時加入專業知識。你認為是否有任何工作/問題可以應用ML方法，但應該留給專家處理（一些考慮因素可能是安全、隱私、道德等）<p>我知道最終這些問題很多都可以簡單地歸結為統計數據和它們的解釋，所以我不確定討論可以/應該/將導致什麼，但我期待著聽到你的意見"
}