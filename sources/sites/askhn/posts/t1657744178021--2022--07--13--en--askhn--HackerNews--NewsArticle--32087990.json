{
  "@type": "NewsArticle",
  "identifier": "2022--07--13--en--askhn--HackerNews--NewsArticle--32087990",
  "url": "https://news.ycombinator.com/item?id=32087990",
  "headline": "Ask HN: How to count metrics from executions of AWS lambdas?",
  "publisher": {
    "@type": "Organization",
    "name": "HackerNews",
    "url": "https://news.ycombinator.com",
    "logo": "https://hn.buzzing.cc/avatar.png"
  },
  "description": "I have all sorts of metrics I would like to count and later query. For example I have a lambda that processes stuff from a queue, and for each batch I would like to save a count like this:<p><pre><code>    {\n      &quot;processes_count&quot;: 6,\n      &quot;timestamp&quot;: 1695422215,\n      &quot;count_by_type&quot;: {\n        &quot;type_a&quot;: 4,\n        &quot;type_b&quot;: 2\n      }\n    }\n</code></pre>\nI would like to dump these pieces somewhere and later have the ability to query how many were processed within a time range.<p>So these are the options I considered:\n1. write the json to the logs, and later have a component (beats?) that processed these logs and send to a timeseries db.\n2. in the end of each execution send it directly to a timeseries db (like elasticearch).<p>What is better in terms of cost / scalability? Are there more options I should consider?",
  "keywords": [
    "Ask HN"
  ],
  "genre": "Ask HN",
  "author": {
    "@type": "Person",
    "name": "shlosky",
    "url": "https://news.ycombinator.com/user?id=shlosky"
  },
  "discussionUrl": "https://news.ycombinator.com/item?id=32087990",
  "sameAs": "https://news.ycombinator.com/item?id=32087990",
  "dateCreated": "2022-07-13T20:29:38.021Z",
  "datePublished": "2022-07-13T19:56:01.000Z",
  "dateModified": "2022-07-13T20:29:38.021Z",
  "interactionStatistic": [
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "LikeAction"
      },
      "userInteractionCount": 1
    },
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "CommentAction"
      },
      "userInteractionCount": 0
    }
  ],
  "headline_zh-Hans": "Ask HN: 如何从AWS lambdas的执行中计算指标？\n",
  "headline_zh-Hant": "Ask HN: 如何從AWS lambdas的執行中計算指標？\n",
  "@context": [
    "https://schema.org",
    {
      "@vocab": "http://schema.org/",
      "@language": "en",
      "headline_zh-Hans": {
        "@id": "headline",
        "@language": "zh-Hans"
      },
      "headline_zh-Hant": {
        "@id": "headline",
        "@language": "zh-Hant"
      },
      "@version": 1.1,
      "description_zh-Hans": {
        "@id": "description",
        "@language": "zh-Hans"
      },
      "description_zh-Hant": {
        "@id": "description",
        "@language": "zh-Hant"
      }
    }
  ],
  "description_zh-Hans": "I have all sorts of metrics I would like to count and later query. For example I have a lambda that processes stuff from a queue, and for each batch I would like to save a count like this:<p><pre><code> {\n      &quot;processes_count&quot;: 6,\n      &quot;timestamp&quot;: 1695422215,\n      &quot;count_by_type&quot;: {\n        &quot;type_a&quot;: 4,\n        &quot;type_b&quot;: 2\n      }\n    }\n</code></pre>\nI would like to dump these pieces somewhere and later have the ability to query how many were processed within a time range.<p>So these are the options I considered:\n1. write the json to the logs, and later have a component (beats?) that processed these logs and send to a timeseries db.\n2. in the end of each execution send it directly to a timeseries db (like elasticearch).<p>What is better in terms of cost / scalability? Are there more options I should consider?\n",
  "description_zh-Hant": "I have all sorts of metrics I would like to count and later query. For example I have a lambda that processes stuff from a queue, and for each batch I would like to save a count like this:<p><pre><code> {\n      &quot;processes_count&quot;: 6,\n      &quot;timestamp&quot;: 1695422215,\n      &quot;count_by_type&quot;: {\n        &quot;type_a&quot;: 4,\n        &quot;type_b&quot;: 2\n      }\n    }\n</code></pre>\nI would like to dump these pieces somewhere and later have the ability to query how many were processed within a time range.<p>So these are the options I considered:\n1. write the json to the logs, and later have a component (beats?) that processed these logs and send to a timeseries db.\n2. in the end of each execution send it directly to a timeseries db (like elasticearch).<p>What is better in terms of cost / scalability? Are there more options I should consider?\n"
}