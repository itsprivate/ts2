{
  "@type": "NewsArticle",
  "identifier": "2022--06--26--en--askhn--HackerNews--NewsArticle--31881725",
  "url": "https://news.ycombinator.com/item?id=31881725",
  "headline": "Ask HN: How do orgs detect conflicting hashes in sub-second timing?",
  "publisher": {
    "@type": "Organization",
    "name": "HackerNews",
    "url": "https://news.ycombinator.com",
    "logo": "https://hn.buzzing.cc/avatar.png"
  },
  "description": "Today I was considering how organizations such as bitly, imgur, reddit, and even github handle hash collision prevention.<p>While for GH it (seems) easier as commit hashes are sufficiently long/unique, for others with character hashes that only span ~6 chars or so, there's bound to be instances where hashes conflict from a statistical standpoint. (iirc reading an article on a hash collision in GH a few years ago here on ycomb)<p>To my mind these orgs have to have a suite tools/algos requesting information from multiple services, checking whether or not a hash has been taken – and those processes have to optimize for time. (e.g. when a user makes a post, what's a reasonable time to do a lookup?)<p>So, what are the considerations which need to be made algorithmically to check such collisions while keeping runtime to an acceptable minimum?",
  "keywords": [
    "Ask HN"
  ],
  "genre": "Ask HN",
  "author": {
    "@type": "Person",
    "name": "adam_ellsworth",
    "url": "https://news.ycombinator.com/user?id=adam_ellsworth"
  },
  "discussionUrl": "https://news.ycombinator.com/item?id=31881725",
  "sameAs": "https://news.ycombinator.com/item?id=31881725",
  "dateCreated": "2022-06-26T07:22:44.427Z",
  "datePublished": "2022-06-26T06:51:08.000Z",
  "dateModified": "2022-06-26T07:22:44.427Z",
  "interactionStatistic": [
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "LikeAction"
      },
      "userInteractionCount": 2
    },
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "CommentAction"
      },
      "userInteractionCount": 0
    }
  ],
  "headline_zh-Hans": "Ask HN: 组织如何在亚秒级时间内检测冲突的哈希值？\n",
  "headline_zh-Hant": "Ask HN: 組織如何在亞秒級時間內檢測衝突的哈希值？\n",
  "@context": [
    "https://schema.org",
    {
      "@vocab": "http://schema.org/",
      "@language": "en",
      "headline_zh-Hans": {
        "@id": "headline",
        "@language": "zh-Hans"
      },
      "headline_zh-Hant": {
        "@id": "headline",
        "@language": "zh-Hant"
      },
      "@version": 1.1,
      "description_zh-Hans": {
        "@id": "description",
        "@language": "zh-Hans"
      },
      "description_zh-Hant": {
        "@id": "description",
        "@language": "zh-Hant"
      }
    }
  ],
  "description_zh-Hans": "今天我在考虑bitly、imgur、reddit甚至github等组织如何处理哈希碰撞的问题。<p>虽然对于GH来说，由于提交的哈希足够长/独特，所以（看起来）比较容易，但对于其他只跨越~6个字符左右的字符哈希，从统计的角度来看，肯定会有哈希冲突的情况。(我记得几年前在ycomb上读过一篇关于GH的哈希碰撞的文章)<p>在我看来，这些组织必须有一套工具/算法，从多个服务中请求信息，检查是否已经采取了哈希 - 这些过程必须优化时间。(例如，当一个用户发了一个帖子，什么是合理的查找时间？)<p>那么，在算法上需要考虑什么，以检查这种碰撞，同时将运行时间保持在可接受的最低限度？\n",
  "description_zh-Hant": "今天我在考慮bitly、imgur、reddit甚至github等組織如何處理哈希碰撞的問題。<p>雖然對於GH來說，由於提交的哈希足夠長/獨特，所以（看起來）比較容易，但對於其他只跨越~6個字符左右的字符哈希，從統計的角度來看，肯定會有哈希衝突的情況。(我記得幾年前在ycomb上讀過一篇關於GH的哈希碰撞的文章)<p>在我看來，這些組織必須有一套工具/算法，從多個服務中請求信息，檢查是否已經採取了哈希 - 這些過程必須優化時間。(例如，當一個用戶發了一個帖子，什麼是合理的查找時間？)<p>那麼，在算法上需要考慮什麼，以檢查這種碰撞，同時將運行時間保持在可接受的最低限度？\n"
}