{
  "@type": "NewsArticle",
  "identifier": "2022--03--20--en--showhn--HackerNews--NewsArticle--30743612",
  "url": "https://news.ycombinator.com/item?id=30743612",
  "headline": "Show HN: Hear what you see: Neural net to convert images to audio",
  "publisher": {
    "@type": "Organization",
    "name": "HackerNews",
    "url": "https://news.ycombinator.com",
    "logo": "https://hn.buzzing.cc/avatar.png"
  },
  "description": "WYSIWHY is a neural network that transforms an input video into an audio sequence in real time. It does so by compressing each image using an autoencoder and interpreting the resulting code as a frequency range.<p>This could potentially be useful for the visually impaired, helping with indoor navigation. It could also be used to transform an infrared or ultraviolet video to sound and thus enable one to perceive otherwise invisible colors.<p>In a usual autoencoder, the elements of the code vector are independent of each other. This makes subtle differences between adjacent elements of the code vector hard to perceive for humans. The resulting audio sequence would sound like indistinguishable white noise. For WYSIWYH thus an encoder is used which hierarchically structures the code, meaning that large differences in the input image result in large differences in the output code. This also results in adjacent elements of the code vector being correlated. This makes the autoencoder’s code more friendly to human perception.",
  "keywords": [
    "Show HN"
  ],
  "genre": "Show HN",
  "author": {
    "@type": "Person",
    "name": "muxamilian",
    "url": "https://news.ycombinator.com/user?id=muxamilian"
  },
  "discussionUrl": "https://news.ycombinator.com/item?id=30743612",
  "sameAs": "https://github.com/muxamilian/wysiwyh",
  "dateCreated": "2022-03-20T15:51:09.873Z",
  "datePublished": "2022-03-20T15:44:12.000Z",
  "dateModified": "2022-03-20T15:51:09.873Z",
  "interactionStatistic": [
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "LikeAction"
      },
      "userInteractionCount": 1
    },
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "CommentAction"
      },
      "userInteractionCount": 0
    }
  ],
  "headline_zh-Hans": "Show HN: 听见你所看到的。将图像转换为音频的神经网络",
  "headline_zh-Hant": "Show HN: 聽見你所看到的。將圖像轉換為音頻的神經網絡",
  "@context": [
    "https://schema.org",
    {
      "@vocab": "http://schema.org/",
      "@language": "en",
      "headline_zh-Hans": {
        "@id": "headline",
        "@language": "zh-Hans"
      },
      "headline_zh-Hant": {
        "@id": "headline",
        "@language": "zh-Hant"
      },
      "@version": 1.1,
      "description_zh-Hans": {
        "@id": "description",
        "@language": "zh-Hans"
      },
      "description_zh-Hant": {
        "@id": "description",
        "@language": "zh-Hant"
      }
    }
  ],
  "description_zh-Hans": "WYSIWHY是一个神经网络，可以将输入的视频实时转化为音频序列。它通过使用自动编码器压缩每个图像，并将产生的代码解释为一个频率范围。<p>这有可能对视力障碍者有用，有助于室内导航。它还可用于将红外线或紫外线视频转换为声音，从而使人们能够感知其他不可见的颜色。<p>在通常的自动编码器中，代码向量的元素是相互独立的。这使得代码向量的相邻元素之间的细微差别对人类来说难以察觉。由此产生的音频序列听起来就像无法区分的白噪声。因此，对于WYSIWYH来说，使用的编码器是分层结构的代码，这意味着输入图像的巨大差异会导致输出代码的巨大差异。这也导致代码向量的相邻元素被关联起来。这使得自动编码器的代码对人类的感知更加友好。",
  "description_zh-Hant": "WYSIWHY是一個神經網絡，可以將輸入的視頻實時轉化為音頻序列。它通過使用自動編碼器壓縮每個圖像，並將產生的代碼解釋為一個頻率範圍。<p>這有可能對視力障礙者有用，有助於室內導航。它還可用於將紅外線或紫外線視頻轉換為聲音，從而使人們能夠感知其他不可見的顏色。<p>在通常的自動編碼器中，代碼向量的元素是相互獨立的。這使得代碼向量的相鄰元素之間的細微差別對人類來說難以察覺。由此產生的音頻序列聽起來就像無法區分的白噪聲。因此，對於WYSIWYH來說，使用的編碼器是分層結構的代碼，這意味著輸入圖像的巨大差異會導致輸出代碼的巨大差異。這也導致代碼向量的相鄰元素被關聯起來。這使得自動編碼器的代碼對人類的感知更加友好。"
}