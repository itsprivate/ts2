{
  "@type": "NewsArticle",
  "identifier": "2022--06--26--en--hackernews--HackerNews--NewsArticle--31883373",
  "url": "https://news.ycombinator.com/item?id=31883373",
  "headline": "Ask HN: GPT-3 reveals my full name to anybody who asks. Can I do anything?",
  "publisher": {
    "@type": "Organization",
    "name": "HackerNews",
    "url": "https://news.ycombinator.com",
    "logo": "https://hn.buzzing.cc/avatar.png"
  },
  "description": "Alternatively: What's the current status of Personally Identifying Information and language models?<p>I try to hide my real name whenever possible, out of an abundance of caution. You can still find it if you search carefully, but in today's hostile internet I see this kind of soft pseudonymity as my digital personal space, and expect to have it respected.<p>When playing around in GPT-3 I tried making sentences with my username. Imagine my surprise when I see it spitting out my (globally unique, unusual) full name!<p>Looking around, I found a paper that says language models spitting out personal information is a problem[1], a Google blog post that says there's not much that can be done[2], and an article that says OpenAI might automatically replace phone numbers in the future but other types of PII are harder to remove[3]. But nothing on what is <i>actually</i> being done.<p>If I had found my personal information on Google search results, or Facebook, I could ask the information to be removed, but GPT-3 seems to have no such support. Are we supposed to accept that large language models may reveal private information, with no recourse?<p>I don't care much about my <i>name</i> being public, but I don't know what else it might have memorized (political affiliations? Sexual preferences? Posts from 13-year old me?). In the age of GDPR this feels like an enormous regression in privacy.<p>[1]: https://arxiv.org/abs/2012.07805<p>[2]: https://ai.googleblog.com/2020/12/privacy-considerations-in-large.html<p>[3]: https://www.theregister.com/2021/03/18/openai_gpt3_data/",
  "keywords": [
    "Ask HN"
  ],
  "genre": "Ask HN",
  "author": {
    "@type": "Person",
    "name": "BoppreH",
    "url": "https://news.ycombinator.com/user?id=BoppreH"
  },
  "discussionUrl": "https://news.ycombinator.com/item?id=31883373",
  "sameAs": "https://news.ycombinator.com/item?id=31883373",
  "dateCreated": "2022-06-26T13:13:31.393Z",
  "datePublished": "2022-06-26T12:37:21.000Z",
  "dateModified": "2022-06-26T13:13:31.393Z",
  "interactionStatistic": [
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "LikeAction"
      },
      "userInteractionCount": 92
    },
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "CommentAction"
      },
      "userInteractionCount": 9
    }
  ],
  "headline_zh-Hans": "Ask HN: GPT-3将我的全名透露给任何询问的人。我可以做什么吗？\n",
  "headline_zh-Hant": "Ask HN: GPT-3將我的全名透露給任何詢問的人。我可以做什麼嗎？\n",
  "@context": [
    "https://schema.org",
    {
      "@vocab": "http://schema.org/",
      "@language": "en",
      "headline_zh-Hans": {
        "@id": "headline",
        "@language": "zh-Hans"
      },
      "headline_zh-Hant": {
        "@id": "headline",
        "@language": "zh-Hant"
      },
      "@version": 1.1,
      "description_zh-Hans": {
        "@id": "description",
        "@language": "zh-Hans"
      },
      "description_zh-Hant": {
        "@id": "description",
        "@language": "zh-Hant"
      }
    }
  ],
  "description_zh-Hans": "Alternatively: What's the current status of Personally Identifying Information and language models?<p>I try to hide my real name whenever possible, out of an abundance of caution. You can still find it if you search carefully, but in today's hostile internet I see this kind of soft pseudonymity as my digital personal space, and expect to have it respected.<p>When playing around in GPT-3 I tried making sentences with my username. Imagine my surprise when I see it spitting out my (globally unique, unusual) full name!<p>Looking around, I found a paper that says language models spitting out personal information is a problem[1], a Google blog post that says there's not much that can be done[2], and an article that says OpenAI might automatically replace phone numbers in the future but other types of PII are harder to remove[3]. But nothing on what is <i>actually</i> being done.<p>If I had found my personal information on Google search results, or Facebook, I could ask the information to be removed, but GPT-3 seems to have no such support. Are we supposed to accept that large language models may reveal private information, with no recourse?<p>I don't care much about my <i>name</i> being public, but I don't know what else it might have memorized (political affiliations? Sexual preferences? Posts from 13-year old me?). In the age of GDPR this feels like an enormous regression in privacy.<p>[1]: https://arxiv.org/abs/2012.07805<p>[2]: https://ai.googleblog.com/2020/12/privacy-considerations-in-large.html<p>[3]: https://www.theregister.com/2021/03/18/openai_gpt3_data/\n",
  "description_zh-Hant": "Alternatively: What's the current status of Personally Identifying Information and language models?<p>I try to hide my real name whenever possible, out of an abundance of caution. You can still find it if you search carefully, but in today's hostile internet I see this kind of soft pseudonymity as my digital personal space, and expect to have it respected.<p>When playing around in GPT-3 I tried making sentences with my username. Imagine my surprise when I see it spitting out my (globally unique, unusual) full name!<p>Looking around, I found a paper that says language models spitting out personal information is a problem[1], a Google blog post that says there's not much that can be done[2], and an article that says OpenAI might automatically replace phone numbers in the future but other types of PII are harder to remove[3]. But nothing on what is <i>actually</i> being done.<p>If I had found my personal information on Google search results, or Facebook, I could ask the information to be removed, but GPT-3 seems to have no such support. Are we supposed to accept that large language models may reveal private information, with no recourse?<p>I don't care much about my <i>name</i> being public, but I don't know what else it might have memorized (political affiliations? Sexual preferences? Posts from 13-year old me?). In the age of GDPR this feels like an enormous regression in privacy.<p>[1]: https://arxiv.org/abs/2012.07805<p>[2]: https://ai.googleblog.com/2020/12/privacy-considerations-in-large.html<p>[3]: https://www.theregister.com/2021/03/18/openai_gpt3_data/\n"
}