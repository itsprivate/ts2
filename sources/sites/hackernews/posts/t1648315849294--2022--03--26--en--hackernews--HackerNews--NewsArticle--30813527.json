{
  "@type": "NewsArticle",
  "identifier": "2022--03--26--en--hackernews--HackerNews--NewsArticle--30813527",
  "url": "https://news.ycombinator.com/item?id=30813527",
  "headline": "Launch HN: Koko (YC W22 Nonprofit) – Online Suicide Prevention Kit",
  "publisher": {
    "@type": "Organization",
    "name": "HackerNews",
    "url": "https://news.ycombinator.com",
    "logo": "https://hn.buzzing.cc/avatar.png"
  },
  "description": "Hi! My name is Rob and I’m working with my cofounder Kareem on Koko (<a href=\"https://www.kokocares.org\" rel=\"nofollow\">https://www.kokocares.org</a>). We’re a nonprofit that provides free digital mental health services to millions of people struggling online — particularly adolescents.<p>Today, we are launching our Online Suicide Prevention Kit (<a href=\"https://www.kokocares.org/suicide-prevention-toolkit\" rel=\"nofollow\">https://www.kokocares.org/suicide-prevention-toolkit</a>). The goal is to help social networks and online communities better support at-risk individuals on their platforms.<p>Many social platforms have built-in lists of keywords that detect mental health-related search terms (e.g., “self-harm” or “depression”). There is already an established practice to suppress content or surface disclaimers for such searches. Search “suicide” on most platforms and you’ll at least get shown a 1-800 number.<p>But there are a few problems with this. The keyword lists always have glaring omissions. Millions of young adults can still easily find dangerous content, such as tips on how to self-harm or kill themselves. And while some platforms redirect users to “emotional support” pages, the resources provided are often underwhelming and lack evidence-base. The most common approach is to provide an overwhelming list of crisis lines (which isn’t particularly helpful to someone who may already be overwhelmed themselves).<p>Here’s our solution: We have a privacy-first native library designed for social networks, streaming services, online communities, forums, etc. It catches common search terms like “kill myself”, “depressed” or “thinspiration”, as well as a huge long-tail of slang terms and evasive language (e.g., “sewerslide” or  “an0rex1a”).<p>The library is written in Rust and matches in under a microsecond. It has language bindings to Python, Go, and Ruby, and all other major runtimes are coming soon. Our keywords are sourced from over 12k known crisis posts and are hand-curated by social and clinical psychologists on our team. We also use text generators like GPT-3 to expand these lists with other keywords beyond our user-generated corpus. The terms are updated regularly based on new patterns that emerge on our support platform, as well as co-listed terms on large social platforms.<p>We also provide evidence-based mental health interventions and resources, to help supplement what online platforms might already provide (though, frankly, many do essentially nothing). Our interventions can be accessed online, for free, without having to download an app. We provide users with online peer support, self-guided mini courses, crisis triage, etc. We have published seven reviewed papers on these interventions and we have two more in prep now. In a randomized controlled trial with Harvard, our services increased the conversion rate to crisis lines by 23%.*<p>This combination —search detection + evidence-based online interventions — enables us to reach users where they are, right at the moment they are reaching out for help. Instead of showing a user an ad or, at worst, harmful content, we can display resources that are actually helpful. We have seen young people search for “proanorexia” content, then click our banner, then engage with our courses, and then show marked improvement in body image perception and a greater motivation to get help offline.<p>Our library collects no data and our interventions are anonymous (we do not collect emails, usernames, IP addresses, phone numbers, etc).<p>Online platforms are heavily (and rightly) criticized for contributing to the youth mental health crisis. But what’s missing from the discussion is how these platforms are uniquely positioned to do something about it. Everyday, millions of people are crying out for help and the most anyone does is throw up a 1-800 number or offer suggestions to “go take a walk” or “reach out to a friend.”<p>Fortunately, we have partnered with a few large social networks that are eager to take the next step. We are now helping over 12,000 people a month with this approach. For users who complete our online interventions, we see significant improvements across clinical outcomes, including hopelessness, body image perception, and self-hatred.<p>This definitely won’t help everyone and nothing can replace direct human-to-human connection. Some at-risk users need far more than we can ever give them with our approach. But it does help some people in profound ways, and that inspires us to keep going.<p>Koko is something I started while I was a graduate student at MIT. I was severely depressed at the time, so I hacked together various technologies to manage my own mental health, as a way to fill the gaps between sessions with my therapist. That was almost ten years ago. I now have a kid of my own and I can see him struggle emotionally, just as I did.<p>Suicide rates for young people have increased dramatically over the past decade.* Since 2019, the rate of suspected suicides for girls aged 12-17 has increased by over 50% [3].* There is nothing more terrifying to me than the thought of a young person dying by suicide. If we can help avert at least one tragedy, it’ll be worth it.<p>We need your support. If you work at a large platform, or even if you just have a small Discord server or subreddit, you can help us by trying out our kit:<p><a href=\"https://www.kokocares.org/suicide-prevention-toolkit\" rel=\"nofollow\">https://www.kokocares.org/suicide-prevention-toolkit</a><p>And please donate! If you care about this issue, please support us: <a href=\"https://every.org/kokocares\" rel=\"nofollow\">https://every.org/kokocares</a><p>If you work at a large social network, or even if you just have a small online community (a Discord server, a subreddit), we think our resources could be helpful. But we’re curious if there are other opportunities we haven’t considered. We would love your feedback on what we’re building, and any technical ideas that might help improve it.<p>* Happy to provide references in the comments - just ask",
  "keywords": [],
  "author": {
    "@type": "Person",
    "name": "robertrmorris",
    "url": "https://news.ycombinator.com/user?id=robertrmorris"
  },
  "discussionUrl": "https://news.ycombinator.com/item?id=30813527",
  "sameAs": "https://news.ycombinator.com/item?id=30813527",
  "dateCreated": "2022-03-26T17:30:49.294Z",
  "datePublished": "2022-03-26T17:12:58.000Z",
  "dateModified": "2022-03-26T17:30:49.294Z",
  "interactionStatistic": [
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "LikeAction"
      },
      "userInteractionCount": 6
    },
    {
      "@type": "InteractionCounter",
      "interactionType": {
        "@type": "CommentAction"
      },
      "userInteractionCount": 0
    }
  ],
  "headline_zh-Hans": "启动HN：Koko（YC W22非营利组织）--在线自杀预防工具包",
  "headline_zh-Hant": "啟動HN：Koko（YC W22非營利組織）--在線自殺預防工具包",
  "@context": [
    "https://schema.org",
    {
      "@vocab": "http://schema.org/",
      "@language": "en",
      "headline_zh-Hans": {
        "@id": "headline",
        "@language": "zh-Hans"
      },
      "headline_zh-Hant": {
        "@id": "headline",
        "@language": "zh-Hant"
      },
      "@version": 1.1,
      "description_zh-Hans": {
        "@id": "description",
        "@language": "zh-Hans"
      },
      "description_zh-Hant": {
        "@id": "description",
        "@language": "zh-Hant"
      }
    }
  ],
  "description_zh-Hans": "嗨！我叫罗伯，我和我的联合创始人卡里姆一起在Koko（<a href=\"https://www.kokocares.org\" rel=\"nofollow\">https://www.kokocares.org</a>）工作。我们是一个非营利组织，为数百万在网上挣扎的人--尤其是青少年--提供免费的数字心理健康服务。<p>今天，我们将推出我们的在线自杀预防工具包（<a href=\"https://www.kokocares.org/suicide-prevention-toolkit\" rel=\"nofollow\">https://www.kokocares.org/suicide-prevention-toolkit</a>）。其目的是帮助社交网络和在线社区在其平台上更好地支持高危人群。<p>许多社交平台都有内置的关键词列表，可以检测与心理健康有关的搜索词（例如，\"自我伤害 \"或 \"抑郁症\"）。对于此类搜索，已经有了抑制内容或浮现免责声明的惯例。在大多数平台上搜索 \"自杀\"，你至少会看到一个1-800的电话号码。<p>但是，这有几个问题。关键字列表总是有明显的遗漏。数以百万计的年轻人仍然可以很容易地找到危险的内容，例如关于如何自我伤害或自杀的提示。而且，尽管一些平台将用户重定向到 \"情感支持 \"页面，但所提供的资源往往不尽人意，而且缺乏证据基础。最常见的方法是提供一个铺天盖地的危机热线列表（这对那些可能已经不堪重负的人来说并没有特别的帮助）。<p>我们的解决方案是这样的。我们有一个隐私优先的原生库，为社交网络、流媒体服务、在线社区、论坛等设计。它可以捕捉常见的搜索词，如 \"自杀\"、\"抑郁 \"或 \"瘦身灵感\"，以及大量的俚语和回避语言的长尾词（如 \"sewerslide \"或 \"an0rex1a\"）。<p>该库由Rust编写，在一微秒内完成匹配。它有与Python、Go和Ruby的语言绑定，所有其他主要的运行机制也即将推出。我们的关键词来自于超过12000个已知的危机帖子，并由我们团队中的社会和临床心理学家手工整理。我们还使用GPT-3等文本生成器，用用户生成的语料库以外的其他关键词扩展这些列表。这些术语会根据我们的支持平台上出现的新模式以及大型社交平台上共同列出的术语定期更新。<p>我们还提供基于证据的心理健康干预措施和资源，以帮助补充在线平台可能已经提供的内容（尽管坦率地说，许多平台基本上什么都没做）。我们的干预措施可以在网上免费获取，无需下载应用程序。我们为用户提供在线同伴支持、自我指导的小型课程、危机分流等。我们已经发表了七篇关于这些干预措施的评论性论文，我们现在还有两篇正在准备中。在与哈佛大学进行的一项随机对照试验中，我们的服务将危机热线的转换率提高了23%。*<p>这种组合--搜索检测+基于证据的在线干预--使我们能够在用户所在的地方，在他们伸出援手的那一刻到达他们身边。与其向用户展示广告或最坏情况下的有害内容，我们可以展示真正有帮助的资源。我们已经看到年轻人搜索 \"亲厌食症 \"的内容，然后点击我们的横幅，然后参与我们的课程，然后在身体形象感知方面显示出明显的改善，并有更大的动力去获得线下帮助。<p>我们的图书馆不收集数据，我们的干预是匿名的（我们不收集电子邮件、用户名、IP地址、电话号码等）。但是，讨论中缺少的是，这些平台是如何在这方面发挥独特作用的。每天都有数以百万计的人在呼救，而人们所做的最多的事情就是抛出一个1-800号码，或者提供 \"去散步 \"或 \"向朋友求助 \"的建议。<p>幸运的是，我们已经与一些大型社交网络合作，它们渴望采取下一步行动。我们现在每月用这种方法帮助超过12,000人。对于完成我们在线干预的用户，我们看到临床结果有了明显的改善，包括无望、身体形象感知和自我憎恨。<p>这肯定不会帮助所有人，没有什么可以取代人与人之间的直接联系。一些高危用户需要的东西远远超过我们的方法所能给予他们的。但它确实以深刻的方式帮助了一些人。",
  "description_zh-Hant": "嗨！我叫羅伯，我和我的聯合創始人卡里姆一起在Koko（<a href=\"https://www.kokocares.org\" rel=\"nofollow\">https://www.kokocares.org</a>）工作。我們是一個非營利組織，為數百萬在網上掙扎的人--尤其是青少年--提供免費的數字心理健康服務。<p>今天，我們將推出我們的在線自殺預防工具包（<a href=\"https://www.kokocares.org/suicide-prevention-toolkit\" rel=\"nofollow\">https://www.kokocares.org/suicide-prevention-toolkit</a>）。其目的是幫助社交網絡和在線社區在其平臺上更好地支持高危人群。<p>許多社交平臺都有內置的關鍵詞列表，可以檢測與心理健康有關的搜索詞（例如，\"自我傷害 \"或 \"抑鬱症\"）。對於此類搜索，已經有了抑制內容或浮現免責聲明的慣例。在大多數平臺上搜索 \"自殺\"，你至少會看到一個1-800的電話號碼。<p>但是，這有幾個問題。關鍵字列表總是有明顯的遺漏。數以百萬計的年輕人仍然可以很容易地找到危險的內容，例如關於如何自我傷害或自殺的提示。而且，儘管一些平臺將用戶重定向到 \"情感支持 \"頁面，但所提供的資源往往不盡人意，而且缺乏證據基礎。最常見的方法是提供一個鋪天蓋地的危機熱線列表（這對那些可能已經不堪重負的人來說並沒有特別的幫助）。<p>我們的解決方案是這樣的。我們有一個隱私優先的原生庫，為社交網絡、流媒體服務、在線社區、論壇等設計。它可以捕捉常見的搜索詞，如 \"自殺\"、\"抑鬱 \"或 \"瘦身靈感\"，以及大量的俚語和迴避語言的長尾詞（如 \"sewerslide \"或 \"an0rex1a\"）。<p>該庫由Rust編寫，在一微秒內完成匹配。它有與Python、Go和Ruby的語言綁定，所有其他主要的運行機制也即將推出。我們的關鍵詞來自於超過12000個已知的危機帖子，並由我們團隊中的社會和臨床心理學家手工整理。我們還使用GPT-3等文本生成器，用用戶生成的語料庫以外的其他關鍵詞擴展這些列表。這些術語會根據我們的支持平臺上出現的新模式以及大型社交平臺上共同列出的術語定期更新。<p>我們還提供基於證據的心理健康干預措施和資源，以幫助補充在線平臺可能已經提供的內容（儘管坦率地說，許多平臺基本上什麼都沒做）。我們的干預措施可以在網上免費獲取，無需下載應用程序。我們為用戶提供在線同伴支持、自我指導的小型課程、危機分流等。我們已經發表了七篇關於這些干預措施的評論性論文，我們現在還有兩篇正在準備中。在與哈佛大學進行的一項隨機對照試驗中，我們的服務將危機熱線的轉換率提高了23%。*<p>這種組合--搜索檢測+基於證據的在線干預--使我們能夠在用戶所在的地方，在他們伸出援手的那一刻到達他們身邊。與其向用戶展示廣告或最壞情況下的有害內容，我們可以展示真正有幫助的資源。我們已經看到年輕人搜索 \"親厭食症 \"的內容，然後點擊我們的橫幅，然後參與我們的課程，然後在身體形象感知方面顯示出明顯的改善，並有更大的動力去獲得線下幫助。<p>我們的圖書館不收集數據，我們的干預是匿名的（我們不收集電子郵件、用戶名、IP地址、電話號碼等）。但是，討論中缺少的是，這些平臺是如何在這方面發揮獨特作用的。每天都有數以百萬計的人在呼救，而人們所做的最多的事情就是拋出一個1-800號碼，或者提供 \"去散步 \"或 \"向朋友求助 \"的建議。<p>幸運的是，我們已經與一些大型社交網絡合作，它們渴望採取下一步行動。我們現在每月用這種方法幫助超過12,000人。對於完成我們在線干預的用戶，我們看到臨床結果有了明顯的改善，包括無望、身體形象感知和自我憎恨。<p>這肯定不會幫助所有人，沒有什麼可以取代人與人之間的直接聯繫。一些高危用戶需要的東西遠遠超過我們的方法所能給予他們的。但它確實以深刻的方式幫助了一些人。"
}